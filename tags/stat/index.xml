<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Stat on loikein</title>
    <link>/tags/stat/</link>
    <description>Recent content in Stat on loikein</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 12 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/stat/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Notes on Econometrics - Practice Part</title>
      <link>/2019/01/notes-stat1-practice/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/notes-stat1-practice/</guid>
      <description>Compare Models Choose Explanatory Variables Choose Approach: OLS / GLS Weird Model  R Workout Data Generation OLS Regression    Warning: under proofreading
All I wanted was a clear &amp;amp; complete guidance (for upcoming exams).
Textbook: A Guide to Modern Econometrics
Compare Models Choose Explanatory Variables  PS2.Q3
Consider the wage regressions from slide 5 (text P86).
1. Compute F-statistics for comparing the loglinear model with and without squared experience.</description>
    </item>
    
    <item>
      <title>Notes on Econometrics - Theory Part</title>
      <link>/2019/01/notes-stat1-theory/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/notes-stat1-theory/</guid>
      <description>Tests &amp;amp; Statistics \(R^2\) t-test F-test (Joint Test) Wald Test BIC &amp;amp; AIC (Nested Model) J Test (Non-Nested Model) PE Test (Linear vs Log) Chow (Breakpoint) Test Durbin-Watson Test (Autocorrelation) Goldfeld-Quandt Test (Heteroskedasticity) Breusch-Pagan (LM) Test (Heteroskedasticity) Breusch-Godfrey Test (Autocorrelation) Box-Pierce Test (Autocorrelation) Sargan Test (GIVE Overidentification) Durbin-Wu-Hausman Test (Endogeneity) Dickey-Fuller Test (Unit Root) Hausman Test (FE vs RE) Read Regression Table  Gauss-Markov Assumptions OLS Error Normality of \(ε\) Unbiasedness of \(s^2\) Consistency of \(s^2\)  OLS Estimator Derive OLS Normality of \(b\) Unbiasedness of \(b\) Consistent of \(b\) (Asymptotic) Efficienty BLUE (Best Linear Unbiased Estimator) CAN (Consistent and Asymptotically Normal)  OLS Model Converge in Probability &amp;amp; Mean Square LLN (Law of Large Numbers) Loglinear Model Elasticity  IV (Instrument Variable) Derive IV IV Estimator \(\hat{β}_{IV}\) GIVE (Generalized IV Estimator)  Heteroskedasticity &amp;amp; Autocorrelation White (Hetero-Consistent) Standard Error HAC (Robust) Standard Error  ML (Maximum Likelihood) Model Assumption Property of \(\hat{θ}\) Asymptotic Covariance Matrix \(V\)  Binary Choice Model Regression Model Probit Model Logit Model Likelihood Ratio  Time Series Types of Process Lag Operator Stationary  Panel Data Entity Fixed Effect Time Fixed Effect Least Squares Dummy Variable (LSDV) Estimator Within Estimator First Difference Estimator Entity and Time Fixed Effect (2-way) Random Effect Feasible GLS (EGLS) Estimator    Warning: under proofreading</description>
    </item>
    
  </channel>
</rss>