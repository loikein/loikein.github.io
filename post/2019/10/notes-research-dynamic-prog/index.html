<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.62.0" />

<title>Notes on Research: Dynamic Programming - loikein&#39;s notes</title>
<meta property="og:title" content="Notes on Research: Dynamic Programming - loikein&#39;s notes">


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-143089736-1', 'auto');
  
  ga('send', 'pageview');
}
</script>


  


<link rel="icon" type="image/x-icon" href="/favicon.ico" />


<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">
<link rel="stylesheet" href="/css/clumsy-toc.css" media="all">




  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/post/" class="nav-logo">
    <img src="/images/loikein-logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>
  <ul class="nav-links">
    
    <li><a href="/post/">Posts</a></li>
    
    <li><a href="/tags/">Tags</a></li>
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/loikein/loikein.github.io">GitHub</a></li>
    
  </ul>
</nav>
      </header>
<main class="content" role="main">
  <article class="article">
    
    <span class="article-duration">14 min read</span>
    
    <h1 class="article-title">Notes on Research: Dynamic Programming</h1>
    
    <span class="article-date">2019/10/07</span>
    
    
    
    <span class="tags">
    
    
    Tags:
    
    <a href='/tags/notes'>notes</a>
    
    <a href='/tags/micro'>micro</a>
    
    <a href='/tags/math'>math</a>
    
    
    
    </span>
    
    <div class="article-content">
      

<div id="TOC">
<ul>
<li><a href="#dynamic-programming-discrete-time">Dynamic Programming: Discrete Time</a>
<ul>
<li><a href="#example-corn-planting">Example: Corn Planting</a></li>
<li><a href="#sequence-problem">Sequence Problem</a></li>
<li><a href="#functional-bellman-equation">Functional (Bellman) Equation</a></li>
<li><a href="#bounded-and-continuous-rewards">Bounded and Continuous Rewards</a></li>
<li><a href="#bellman-operator">Bellman Operator</a></li>
</ul></li>
<li><a href="#stochastic-dynamic-programming">Stochastic Dynamic Programming</a>
<ul>
<li><a href="#example-corn-rain">Example: Corn &amp; Rain</a></li>
<li><a href="#random-shocks">Random Shocks</a></li>
<li><a href="#example-kiefer-1989">Example: <span>Kiefer (1989)</span></a></li>
</ul></li>
<li><a href="#controlled-diffusion-and-optimal-stopping">Controlled Diffusion and Optimal Stopping</a>
<ul>
<li><a href="#wiener-process">Wiener Process</a></li>
<li><a href="#diffusion-process">Diffusion Process</a></li>
<li><a href="#itos-lemma">Ito’s Lemma</a></li>
<li><a href="#example-geometric-brownian-motion">Example: Geometric Brownian Motion</a></li>
<li><a href="#optimal-control">Optimal Control</a></li>
<li><a href="#binary-case-optimal-stopping">Binary Case: Optimal Stopping</a></li>
<li><a href="#example-irreversible-investment-under-uncertainty">Example: Irreversible Investment Under Uncertainty</a></li>
<li><a href="#poisson-process">Poisson Process</a></li>
<li><a href="#optimal-exploration-in-two-armed-bandit-problem">Optimal Exploration in Two-Armed Bandit Problem</a></li>
</ul></li>
<li><a href="#presentation-term-paper">Presentation &amp; Term Paper</a>
<ul>
<li><a href="#besanko-tong-wu-2018">Besanko Tong Wu 2018</a></li>
<li><a href="#bonatti-hoerner-2011">Bonatti Hoerner 2011</a></li>
<li><a href="#branco-sun-villas-boas-2012">Branco Sun Villas-Boas 2012</a></li>
<li><a href="#che-hoerner-2018">Che Hoerner 2018</a></li>
<li><a href="#halac-kartik-liu-2016">Halac Kartik Liu 2016</a></li>
<li><a href="#manso-2011">Manso 2011</a></li>
<li><a href="#strulovici-2010">Strulovici 2010</a></li>
</ul></li>
<li><a href="#kremer-mansour-perry-2014-my-bit">Kremer Mansour Perry 2014 (My Bit)</a>
<ul>
<li><a href="#motivation">Motivation</a></li>
<li><a href="#model">Model</a></li>
<li><a href="#result">Result</a></li>
<li><a href="#intuition">Intuition</a></li>
<li><a href="#my-thoughts">My thoughts</a></li>
</ul></li>
</ul>
</div>

<p>wrt means with respect to</p>
<p>Textbook: <a href="http://93.174.95.27/book/index.php?md5=95BF65ECABD0CB44AF57089D7668D426">Nancy L. Stokey, Robert E. Lucas Jr., Edward C. Prescott - Recursive Methods in Economic Dynamics</a> (S&amp;L)</p>
<div id="dynamic-programming-discrete-time" class="section level2">
<h2>Dynamic Programming: Discrete Time</h2>
<p>also see <a href="../../01/notes-math-optimization-dynamics/#dynamics">Notes on Mathematics - Optimization and Dynamics</a></p>
<div id="example-corn-planting" class="section level3">
<h3>Example: Corn Planting</h3>
<ul>
<li>Time: <span class="math inline">\(t=0,1,2,\dots\)</span></li>
<li>Initial # of seeds: <span class="math inline">\(k_0\)</span></li>
<li>Plant: <span class="math inline">\(k_t\)</span></li>
<li>Harvest: <span class="math inline">\(f(k_t)\)</span></li>
<li>Consumption: <span class="math inline">\(c_t\leq f(k_t)\)</span></li>
<li>Next period plant: <span class="math inline">\(k_{t+1} = f(k_t) - c_t\)</span></li>
<li>Utility function: <span class="math inline">\(U(c_t)\)</span>
<ul>
<li>Increasing &amp; concave</li>
</ul></li>
<li>Discount: <span class="math inline">\(0&lt;β&lt;1\)</span></li>
<li>Sequence Problem (SP):
<span class="math display">\[\begin{aligned}\max_{c_t} &amp;&amp; \sum_{t=0}^{\infty} β^t\cdot U(c_t) \end{aligned}\]</span>
s.t.
<span class="math display">\[\begin{aligned}(BC) &amp;&amp; k_{t+1} = f(k_t) - c_t \end{aligned}\]</span></li>
<li>Substituting for <span class="math inline">\(c_t\)</span>:
<span class="math display">\[\begin{aligned}\max_{k_t} &amp;&amp; \sum_{t=0}^{\infty} β^t\cdot U\big(f(k_t) - k_{t+1}\big) \end{aligned}\]</span>
s.t.
<span class="math display">\[\begin{aligned}(BC) &amp;&amp; k_{t+1} \in\big[ 0, f(k_t)\big]\end{aligned}\]</span></li>
<li>Find optimal policy (plan) that maximises SP:
<span class="math display">\[\begin{aligned}k_{t+1} &amp;= g(k_t) \\ &amp;\in\big[ 0, f(k_t)\big] \end{aligned}\]</span>
<ul>
<li>Time-invariant</li>
<li>Recursive approach</li>
</ul></li>
</ul>
</div>
<div id="sequence-problem" class="section level3">
<h3>Sequence Problem</h3>
<ul>
<li>SP:
<span class="math display">\[\begin{aligned}\max_{x_1,x_2,\dots} &amp;&amp; \sum_{t=0}^{\infty} β^t\cdot F(x_t, x_{t+1}) \end{aligned}\]</span>
s.t. <span class="math inline">\(x_{t+1}\in Γ(x_t)\)</span> for all <span class="math inline">\(t\)</span><br />
and <span class="math inline">\(x_0 = x\)</span></li>
<li>Elements of SP
<ul>
<li>State space: <span class="math inline">\(X\)</span>, <span class="math inline">\(x_t\in X\)</span> for all <span class="math inline">\(t\)</span></li>
<li>Initial state: <span class="math inline">\(x_0\in X\)</span></li>
<li>Feasibility correspondence: <span class="math inline">\(Γ(x_t)\in X\)</span> for all <span class="math inline">\(t\)</span></li>
<li>One period reward function: <span class="math inline">\(F(x_t, x_{t+1})\)</span></li>
<li>Discount factor: <span class="math inline">\(β\)</span></li>
</ul></li>
</ul>
</div>
<div id="functional-bellman-equation" class="section level3">
<h3>Functional (Bellman) Equation</h3>
<ul>
<li>Functional Equation (FE): (<span class="math inline">\(y := x_{t+1}\)</span>)
<span class="math display">\[\begin{aligned}(FE) &amp;&amp; v(x) = \max_{y\in Γ(x)} \ \big\{ \underbrace{F(x,y)}_{\text{Current reward}} + \underbrace{β\cdot v(y)}_{\text{Continuation value}} \big\} \end{aligned}\]</span>
<ul>
<li>Solution: Value Function <span class="math inline">\(v^*(x)\)</span></li>
<li>any optimal solution <span class="math inline">\(x\)</span> given by <span class="math inline">\(v^*(x)\)</span> must achieve the max</li>
</ul></li>
<li>Value Function (VF) for SP:
<span class="math display">\[\begin{aligned}(VF) &amp;&amp; v^*(x_0) = \max_{x_1,x_2,\dots} \ \sum_{t=0}^{\infty} β^t\cdot F(x_t,x_{t+1}) \end{aligned}\]</span>
s.t. <span class="math inline">\(x_{t+1} \in Γ(x_t)\)</span><br />
Let <span class="math inline">\(s=t-1\)</span>, VF can be rewritten as:
<span class="math display">\[\begin{aligned}v^*(x_0) &amp;= \max_{x_1\in Γ(x_0)}\Big\{ \underbrace{F(x_0,x_1)}_{t=0} + \max_{x_2,x_3,\dots} \ \sum_{t=1}^{\infty} β^t\cdot F(x_t,x_{t+1})\Big\} \\
&amp;= \max_{x_1\in Γ(x_0)}\Big\{ F(x_0,x_1) + \max_{x_2,x_3,\dots} \ \sum_{s=0}^{\infty} β^{s+1}\cdot F(x_{s+1},x_{s+2})\Big\} \\
&amp;= \max_{x_1\in Γ(x_0)}\Big\{ F(x_0,x_1) + β\cdot \Big[ \max_{x_2,x_3,\dots} \ \sum_{s=0}^{\infty} β^s\cdot F(x_{s+1},x_{s+2})\Big]\Big\} \\
&amp;= \max_{x_1\in Γ(x_0)}\Big\{ F(x_0,x_1) + β\cdot v^*(x_1)\Big\} \end{aligned}\]</span>
therefore, an optimal <span class="math inline">\(x_1\)</span> for SP must also maximise RHS of VF</li>
<li>How to find <span class="math inline">\(v(x)\)</span>?
<ul>
<li>Start with a guess: <span class="math inline">\(v_0: X\to\mathbb{R}\)</span></li>
<li>Compute for <span class="math inline">\(j=0,1,2,\dots\)</span> <span class="math display">\[v_{j+1}(x) = \max_{y\in Γ(x)}\Big\{ F(x,y) + β\cdot v_j(y) \Big\}\]</span></li>
<li>Converges to function <span class="math inline">\(v(x)\)</span> s.t.
<span class="math display">\[v(x) = \max_{y\in Γ(x)}\Big\{ F(x,y) + β\cdot v(y) \Big\}\]</span></li>
</ul></li>
</ul>
<!-- 
- Conditions for $v = v^*$
    - $F$ is __Continuous + Bounded__
    - $Γ(x)$ is __Compact__
 -->
</div>
<div id="bounded-and-continuous-rewards" class="section level3">
<h3>Bounded and Continuous Rewards</h3>
<ul>
<li><span class="math inline">\(X\subset \mathbb{R}^l\)</span></li>
<li>For all <span class="math inline">\(x\in X\)</span>, <span class="math inline">\(Γ(x)\subset X\)</span></li>
<li><span class="math inline">\(Γ(x)\neq\emptyset\)</span></li>
<li><span class="math inline">\(Γ(x)\)</span> varies continuously with <span class="math inline">\(x\)</span></li>
<li>Let <span class="math inline">\(A\)</span> be the (hypo- or sub-)graph of <span class="math inline">\(Γ\)</span>
<span class="math display">\[A = \{(x,y)\in X\times X : y\in Γ(x)\}\]</span>
<ul>
<li><span class="math inline">\(F: A\to\mathbb{R}\)</span> is <strong>Bounded + Continuous</strong></li>
</ul></li>
</ul>
<blockquote>
<p>Observation<br />
<span class="math inline">\(v^*\)</span> is bounded</p>
</blockquote>
<p>Suppose <span class="math inline">\(-L\leq F(x,y)\leq L\)</span> for some <span class="math inline">\(L&gt;0\)</span>, and <span class="math inline">\((x,y)\in A\)</span>
<span class="math display">\[\begin{aligned}\sum_{t=0}^{\infty} β^t\cdot F(x_t,x_{t+1}) &amp;\leq \sum_{t=0}^{\infty} β^t\cdot L = \frac{L}{1-β} \\
\sum_{t=0}^{\infty} β^t\cdot F(x_t,x_{t+1}) &amp;\geq \sum_{t=0}^{\infty} β^t\cdot (-L) = -\frac{L}{1-β} \end{aligned}\]</span>
Therefore, one can define <span class="math inline">\(C(X)\)</span> the set of all bounded and continuous functions for <span class="math inline">\(X\to\mathbb{R}\)</span><br />
<span class="math inline">\(\implies v^*\in C(X)\)</span></p>
<blockquote>
<p>Theorem<br />
<span class="math inline">\(v^*\)</span> is the unique solution of (FE) in <span class="math inline">\(C(X)\)</span></p>
</blockquote>
<p>Let <span class="math inline">\(G(x) = \text{argmax}_{y\in Γ(x)} \ \{F(x,y) + β\cdot v^*(y) \}\)</span><br />
<span class="math inline">\(G(x)\neq\emptyset\)</span><br />
<span class="math inline">\(\implies\)</span> plan <span class="math inline">\((x_1,x_2,\dots)\)</span> is optimal <span class="math inline">\(\iff x_{t+1}\in G(x_t)\)</span> for all <span class="math inline">\(t\geq 0\)</span><br />
Given any <span class="math inline">\(v_0\in C(X)\)</span>, let <span class="math inline">\(v_n = T_v^n = T\cdots T_{v_0}\)</span><br />
<span class="math inline">\(\implies v_n\to v^*\)</span> as <span class="math inline">\(n\to\infty\)</span></p>
</div>
<div id="bellman-operator" class="section level3">
<h3>Bellman Operator</h3>
<ul>
<li>Bellman operator: <span class="math inline">\(T: C(X)\to C(X)\)</span><br />
for any <span class="math inline">\(v\in C(X)\)</span>, <span class="math inline">\(T_v\in C(X)\)</span> gives<br />
<span class="math display">\[(T_v)(x) = \max_{y\in Γ(x)} \ \{F(x,y) + β\cdot v(y) \}\]</span>
<ul>
<li>Monotonic</li>
<li>Concave (Discounting?)</li>
<li>Differentiable</li>
</ul></li>
</ul>
<blockquote>
<p>Bellman operator is monotonic</p>
</blockquote>
<p>Suppose:<br />
<span class="math inline">\(F\)</span> is strictly increasing wrt current state <span class="math inline">\(x_t\)</span><br />
<span class="math inline">\(Γ\)</span> is monotonic: <span class="math inline">\(x\leq x&#39;\implies Γ(x)\leq Γ(x&#39;)\)</span><br />
<span class="math inline">\(\implies v^*\)</span> is strictly increasing<br />
Idea: <span class="math inline">\(T\)</span> preserves monotonicity, so the fixed point must be monotonic too</p>
<blockquote>
<p>Bellman operator is concave</p>
</blockquote>
<p>Suppose:<br />
<span class="math inline">\(X\subset \mathbb{R}^l\)</span> is convex<br />
<span class="math inline">\(F\)</span> is strictly concave wrt the current state<br />
<span class="math inline">\(Γ\)</span> is convex: <span class="math inline">\(A\)</span> is convex<br />
<span class="math inline">\(\implies v^*\)</span> is strictly concave<br />
and optimal policy correspondence <span class="math inline">\(G(x)\)</span> is single-valued<br />
<span class="math inline">\(\implies G(x)\)</span> is continuous<br />
<span class="math inline">\(\implies\)</span> exists a unique optimal plan for <span class="math inline">\(t=0,1,\dots\)</span>:
<span class="math display">\[x_{t+1} = g(x_t)\]</span></p>
<blockquote>
<p>Bellman operator is differentiable</p>
</blockquote>
<p>Suppose:<br />
<span class="math inline">\(F\)</span> is continuously differentiable wrt current state <span class="math inline">\(x_t\in\text{int} (A)\)</span><br />
<span class="math inline">\(\implies v^*\)</span> is continuously differentiable for <span class="math inline">\(x\in\text{int} (A)\)</span></p>
</div>
</div>
<div id="stochastic-dynamic-programming" class="section level2">
<h2>Stochastic Dynamic Programming</h2>
<div id="example-corn-rain" class="section level3">
<h3>Example: Corn &amp; Rain</h3>
<ul>
<li>Shocks hit before actions</li>
<li>In each period <span class="math inline">\(t\)</span>, timing:
<ol style="list-style-type: decimal">
<li>Plant <span class="math inline">\(k_t\)</span></li>
<li>Rain amount <span class="math inline">\(z_t\)</span></li>
<li>Harvest <span class="math inline">\(f(k_t, z_t)\)</span></li>
<li>Save <span class="math inline">\(k_{t+1}\)</span> for next period</li>
</ol></li>
</ul>
</div>
<div id="random-shocks" class="section level3">
<h3>Random Shocks</h3>
<ul>
<li>Current state: <span class="math inline">\((x,z)\)</span></li>
<li>Shock <span class="math inline">\(z\)</span> follows a Markov chain
<ul>
<li>Distribution of <span class="math inline">\(z&#39;:= z_{t+1}\)</span> depends on only <span class="math inline">\(z := z_t\)</span></li>
</ul></li>
<li>Bellman Equation:
<span class="math display">\[\begin{aligned}(FE) &amp;&amp; v(x,z) = \max_{y\in Γ(x,z)} \ \{ F(x,y,z) + β\cdot E\big[v(y, z&#39;)\big| z\big]\} \end{aligned}\]</span></li>
<li>iid shocks:</li>
</ul>
</div>
<div id="example-kiefer-1989" class="section level3">
<h3>Example: <a href="https://www.sciencedirect.com/science/article/pii/0165188989900183">Kiefer (1989)</a></h3>
<ul>
<li>Monopolist</li>
<li>Inverse demand: <span class="math inline">\(p = α + βq + ε\)</span></li>
<li>Assumptions
<ul>
<li><span class="math inline">\(ε\overset{iid}{\sim}\)</span> some known distribution, <span class="math inline">\(E[ε]=0\)</span></li>
<li>Possible states: <span class="math inline">\((α,β)\in\{(a_1,b_1), \ (a_2,b_2)\}\)</span></li>
</ul></li>
<li>Belief (state variable):
<span class="math display">\[μ_t = Pr\big((α,β) = (a_1,b_1)\ \big|\text{ info till period } t-1\big)\]</span></li>
<li>Profit:
<span class="math display">\[π = E\Big[\sum δ^t\cdot\big(p_t q_t - c(q_t)\big)\Big]\]</span></li>
<li>Predictive distribution for <span class="math inline">\(p\ |\ q\)</span>:
<span class="math display">\[\begin{aligned}f_1(p\ |\ q) &amp;= \text{density of }p\text{ when } (α,β) = (a_1,b_1) \\
f_2(p\ |\ q) &amp;= \text{density of }p\text{ when } (α,β) = (a_2,b_2) \\
f(p\ |\ q,μ_t) &amp;= μ_t\cdot f_1(p\ |\ q) + (1-μ_t)\cdot f_2(p\ |\ q) \end{aligned}\]</span></li>
<li>Updating belief (<span class="math inline">\(Γ\)</span>) (Bayes’ Rule):
<span class="math display">\[\begin{aligned}Pr(A\ |\ B)&amp;= \frac{Pr(A\cap B)}{Pr(B)} = \frac{Pr(A)\cdot Pr(B\ |\ A)}{Pr(B)} \\
Pr(\text{next state is also 1}) &amp;= \frac{Pr(\text{state 1})}{Pr(\text{seeing }p\ |\ q)} \\
μ_{t+1} &amp;= \frac{μ_t\cdot f_1(p\ |\ q)}{f(p\ |\ q,μ_t)} \\\end{aligned}\]</span></li>
<li>Bellman Equation:
<span class="math display">\[\begin{aligned}(FE) &amp;&amp; v(μ) = \max_{q\geq 0}\ \Big\{ &amp;\overbrace{μ(a_1 + b_1\cdot q)\cdot q + (1-μ)(a_2 + b_2\cdot q)\cdot q - c(q)}^{\text{Expected current reward}} \\
&amp;&amp; &amp;+ \underbrace{δ\cdot E[v(μ&#39;)\ |\ q] }_{\text{Expected continuous value}}\Big\} \end{aligned}\]</span></li>
<li><span class="math inline">\(v^*\)</span> is a convex function of <span class="math inline">\(μ\)</span><br />
given <span class="math inline">\(μ_0\)</span> and <span class="math inline">\(v^*_0\)</span>, overall payoff for plan <span class="math inline">\(π_0\)</span> is <span class="math display">\[μ\cdot\text{payoff in state 1}+(1-μ)\cdot\text{payoff in state 2}\]</span>
<span class="math inline">\(\implies\)</span> payoff for <span class="math inline">\(π_0\)</span> is linear in <span class="math inline">\(μ\)</span><br />
<span class="math inline">\(\implies\)</span> following the same plan <span class="math inline">\(π_0\)</span> for some <span class="math inline">\(μ_0&#39;\)</span>, the payoff is linear<br />
<span class="math inline">\(\implies\)</span> re-optimize <span class="math inline">\(v^*\)</span> gives weakly larger than the linear payoff<br />
This ends up in risk-loving behaviour wrs <span class="math inline">\(μ\)</span>: more information is good</li>
</ul>
</div>
</div>
<div id="controlled-diffusion-and-optimal-stopping" class="section level2">
<h2>Controlled Diffusion and Optimal Stopping</h2>
<div id="wiener-process" class="section level3">
<h3>Wiener Process</h3>
<ul>
<li>Stochastic process <span class="math inline">\(z(t)\)</span>, <span class="math inline">\(t\in\mathbb{R}_+\)</span></li>
<li>Definition
<ul>
<li><span class="math inline">\(z(0)=0\)</span></li>
<li>Normal increments: for all <span class="math inline">\(t&#39;&gt;t\)</span>, <span class="math display">\[\begin{aligned}\big(z(t&#39;) - z(t)\big) &amp;\sim \mathcal{N}(0, t&#39;-t) \\z(t&#39;) - z(t) &amp;= ε\sqrt{t&#39;-t} \\ ε\sim\mathcal{N}(0,1) \\ dz &amp;= ε\sqrt{dt} \end{aligned}\]</span></li>
<li>Independent increments: for all <span class="math inline">\(t_0&lt;t_1&lt;t_2&lt;t_3\)</span>, <span class="math display">\[E\big[\big(z(t_1)-z(t_0)\big)\cdot\big(z(t_3)-z(t_2)\big)\big]=0\]</span></li>
<li>All sample paths are continuous</li>
</ul></li>
<li>Conclusion
<ul>
<li>Stationary &amp; independent Gaussian increments</li>
<li>Sample path are nowhere differentiable</li>
<li>Markov process</li>
</ul></li>
</ul>
<blockquote>
<p>Wiener process as the continuous limit of a discrete random walk</p>
</blockquote>
<p>Divide the timeline <span class="math inline">\([0,\infty)\)</span> into intervals of equal length <span class="math inline">\(Δt&gt;0\)</span><br />
Consider random walk <span class="math inline">\(x(t)\)</span> that goes up or down independently by <span class="math inline">\(h\)</span> at the end of each <span class="math inline">\(Δt\)</span><br />
<span class="math display">\[\begin{aligned}Δx &amp;= x(t+Δt) - x(t) =\begin{cases}h &amp; Pr=p \\ -h &amp; Pr=1-p \end{cases}\\
E[Δx] &amp;= p\cdot h + (1-p)\cdot(-h)\\
&amp;= h(2p-1) \\
Var(Δx) &amp;= E[(Δx)^2] - \big(E[Δx]\big)^2 \\
&amp;= h - h^2(2p-1)^2\\
&amp;= 4h^2\cdot p(1-p)\end{aligned}\]</span>
Let <span class="math inline">\(t&#39;-t = n\cdot Δt\)</span> s.t. there are <span class="math inline">\(n\)</span> steps of size <span class="math inline">\(Δt\)</span> between <span class="math inline">\(t\)</span> and <span class="math inline">\(t&#39;\)</span><br />
Since increments are independent,
<span class="math display">\[\begin{aligned}E\big[x(t&#39;)-x(t)\big] &amp;= E\Big[\sum_{k=1}^n \big(x(t+k\cdot Δt - x(t + (k-1)\cdot Δt)\big) \Big] \\
&amp;= n\cdot E[Δx] \\
&amp;= n\cdot h(2p-1) \\
&amp;= \frac{t&#39;-t}{Δt}\cdot h(2p-1)\\
Var\big(x(t&#39;)-x(t)\big) &amp;= n\cdot Var(Δx) \\
&amp;= \frac{t&#39;-t}{Δt}\cdot 4h^2\cdot p(1-p)\end{aligned}\]</span>
We want <span class="math inline">\(E\big[x(t&#39;)-x(t)\big] \overset{!}{=} E\big[z(t&#39;) - z(t)\big]=0\)</span><br />
<span class="math inline">\(\implies p=\frac{1}{2}\)</span>
We want <span class="math inline">\(Var\big(x(t&#39;)-x(t)\big) \overset{!}{=} Var\big(z(t&#39;) - z(t)\big) = t&#39;-t\)</span><br />
<span class="math inline">\(\implies h^2 = Δt\)</span><br />
Therefore, the increment <span class="math inline">\(x(t&#39;)-x(t)\)</span> when <span class="math inline">\(Δt\to 0\)</span> and <span class="math inline">\(n\to\infty\)</span> is the sum of infinitely many Bernoulli variables<br />
By CLT, <span class="math inline">\(x(t&#39;)-x(t)\sim\mathcal{N}(0,t&#39;-t)\)</span><br />
<span class="math inline">\(\implies x(t)\)</span> is a Wiener Process</p>
<blockquote>
<p>Infinite variation
Over the length of <span class="math inline">\(t&#39;-t\)</span>, all paths of Wiener process travel an infinite distance</p>
</blockquote>
<p>As <span class="math inline">\(Δt\to 0\)</span>,
<span class="math display">\[\begin{aligned}n\cdot h &amp;= \frac{t&#39;-t}{Δt}\cdot\sqrt{Δt} \\
&amp;= \frac{t&#39;-t}{\sqrt{Δt}}\to \infty \end{aligned}\]</span></p>
<blockquote>
<p>All sample paths of Wiener process are nowhere differentiable</p>
</blockquote>
<p>As <span class="math inline">\(Δt\to 0\)</span>,
<span class="math display">\[\begin{aligned}\frac{|Δx|}{Δt} &amp;= \frac{h}{Δt} \\
&amp;= \frac{\sqrt{Δt}}{Δt} \\
&amp;= \frac{1}{\sqrt{Δt}} \to\infty\end{aligned}\]</span></p>
</div>
<div id="diffusion-process" class="section level3">
<h3>Diffusion Process</h3>
<ul>
<li>Diffusion process:
<span class="math display">\[dx = \underbrace{a(t,x)\, dt}_{\text{Drift}} + \underbrace{b(t,x)\, dz}_{\text{Noise (Diffusion)}} \]</span>
<ul>
<li>Stochastic differential equation (SDE)</li>
<li>If only has <span class="math inline">\(a(t,x)\, dt\)</span>, can re-write as <span class="math inline">\(\frac{dx}{dt}=a(t,x)\)</span> (ODE)</li>
<li><span class="math inline">\(z\)</span> is a Wiener process: <span class="math inline">\(\frac{dx}{dz}\)</span> is not defined!</li>
</ul></li>
<li>Since <span class="math inline">\(dz = ε\sqrt{dt}\)</span>
<span class="math display">\[\begin{aligned}E[dz] &amp;= E[ε\sqrt{dt}] = 0\\
Var(dz) &amp;= E\big[(ε\sqrt{dt})^2\big] = dt \end{aligned}\]</span>
Therefore,
<span class="math display">\[\begin{aligned}E[dx] &amp;= a(t,x)\, dt + b(t,x)\, E[dz] = a(t,x)\, dt\\
Var(dx) &amp;= E[(dx)^2] - E[dx]^2 \\
&amp;= E\big[(a(t,x)\, dt)^2 + 2a(t,x)b(t,x)\, dtdz + b(t,x)^2\, (dz)^2 \big] - (a(t,x)\, dt)^2\\
&amp;= E\big[2a(t,x)b(t,x)\, dtdz + b(t,x)^2\, (dz)^2 \big]\\
&amp;= b(t,x)^2\, dt\end{aligned}\]</span></li>
</ul>
<blockquote>
<p>Examples</p>
</blockquote>
<ol style="list-style-type: decimal">
<li>Brownian motion: <span class="math inline">\(α,σ\in\mathbb{R}\)</span>
<span class="math display">\[\begin{aligned}dx &amp;= α\, dt + σ\, dz \\
x(t) &amp;= x(0) +αt + σz(t) \end{aligned}\]</span></li>
<li>Geometric Brownian motion (standard asset price model)
<span class="math display">\[dx = αx\, dt + σx\, dz\]</span></li>
<li>Mean-reverting process (Ornstein-Uhlenbeck process) (interest rate model)
<span class="math display">\[dx = α(\bar{x}-x)\, dt + σ\, dz \]</span></li>
</ol>
</div>
<div id="itos-lemma" class="section level3">
<h3>Ito’s Lemma</h3>
<ul>
<li>Functions that take a diffusion process as argument
<span class="math display">\[\begin{aligned}dx &amp;= a(t,x)\, dt+ b(t,x)\, dz\\
y(t) &amp;= f(t, x(t)) \end{aligned}\]</span></li>
<li>Ito’s lemma: let <span class="math inline">\(z(t)\)</span> be a Wiener process, <span class="math inline">\(x(t)\)</span> a diffusion process, <span class="math inline">\(y(t) = f(t, x(t))\)</span><br />
If <span class="math inline">\(f\)</span> has continuous direvatives <span class="math inline">\(f_t\)</span>, <span class="math inline">\(f_x\)</span> and <span class="math inline">\(f_{xx}\)</span>,<br />
then <span class="math inline">\(y(t)\)</span> is a diffusion process s.t.
<span class="math display">\[\begin{aligned}dy &amp;= f_t(t,x)\, dt + \underbrace{f_x(t,x)\, dx} + \frac{1}{2} b(t,x)^2\cdot f_{xx}(t,x)\, dt \\
&amp;= \Big[f_t(t,x) + \underbrace{a(t,x)\cdot f_x(t,x)} + \frac{1}{2} b(t,x)^2\cdot f_{xx}(t,x) \Big]\, dt + \underbrace{b(t,x)\cdot f_x(t,x)\, dz}\end{aligned}\]</span></li>
</ul>
</div>
<div id="example-geometric-brownian-motion" class="section level3">
<h3>Example: Geometric Brownian Motion</h3>
<p>Geometric Brownian Motion:
<span class="math display">\[dx = αx\, dt + σx\, dz\]</span>
<span class="math inline">\(f(x) = \ln (x)\implies f&#39;(x) = \frac{1}{x}\)</span>, <span class="math inline">\(f&#39;&#39;(x) = -\frac{1}{x^2}\)</span><br />
Therefore,
<span class="math display">\[\begin{aligned}dy &amp;= f&#39;αx + \frac{1}{2}σ^2x^2f&#39;&#39;\, dt \\
&amp;= \frac{1}{x}(αx\, dt + σx\, dz) + \frac{1}{2}σ^2x^2(-\frac{1}{x^2})\, dt \\
&amp;= \underbrace{(α-\frac{1}{2}σ^2)}_{\text{Concavity}}\, dt + σ\, dz \end{aligned}\]</span>
write out <span class="math inline">\(y\)</span>
<span class="math display">\[\begin{aligned}y(t) = y_0 + (α-\frac{1}{2}σ^2)t + σz(t) \end{aligned}\]</span>
since <span class="math inline">\(y=\ln (x)\)</span>, <span class="math inline">\(x=e^y\)</span>
<span class="math display">\[\begin{aligned}x(t) &amp;= \exp\big( y_0 +(α-\frac{1}{2}σ^2)t + σz(t)\big) \\
&amp;= x_0\cdot\exp\big((α-\frac{1}{2}σ^2)t + σz(t)\big)  \end{aligned}\]</span>
Conclusions:</p>
<ul>
<li>If <span class="math inline">\(x_0\neq 0\)</span>, then <span class="math inline">\(x(t)\)</span> never reaches <span class="math inline">\(0\)</span></li>
<li><span class="math inline">\(x(t)\sim\mathcal{N}\)</span></li>
<li>Mean of <span class="math inline">\(x(t)\)</span>:
<span class="math display">\[\begin{aligned}E[x(t)] &amp;= E[e^{y(t)}]\\&amp;= x_0\cdot E\Big[\exp\big((α-\frac{1}{2}σ^2)t + σz(t)\big)\Big]\\&amp;= x_0\cdot\exp\big((α-\frac{1}{2}σ^2)t+\frac{1}{2}σ^2t\big)\\&amp;=x_0\cdot e^{αt}\end{aligned}\]</span></li>
</ul>
</div>
<div id="optimal-control" class="section level3">
<h3>Optimal Control</h3>
<ul>
<li>Problem: <span class="math display">\[\begin{aligned}\max &amp;&amp; E\Big[\int_0^{\infty} e^{-rt}y\big(t,x(t),u(t)\big)\, dt \Big] \end{aligned}\]</span></li>
<li><span class="math inline">\(r&gt;0\)</span></li>
<li><span class="math inline">\(x\)</span> is a controlled diffusion process:
<span class="math display">\[dx = a(t,x,u)\, dt + b(t,x,u)\, dz\]</span></li>
<li>Constraints: <span class="math inline">\(u\in U\)</span></li>
<li>Initial state: <span class="math inline">\(x(0)=x_0\)</span></li>
<li>Highest possible value (VF) of objective from some <span class="math inline">\(t_0\)</span>, discounting future rewards:
<span class="math display">\[v(t_0,x_0) = \max\ E\Big[\int_{t_0}^{\infty} e^{-r(t-t_0)}y\big(t,x(t),u(t)\big)\, dt \Big]\]</span>
s.t. <span class="math inline">\(dx = a(t,x,u)\, dt + b(t,x,u)\, dz\)</span>, <span class="math inline">\(u\in U\)</span></li>
<li>Recursive process: let <span class="math inline">\(Δt&gt;0\)</span>,
<span class="math display">\[\begin{aligned}v(t_0,x_0) &amp;= \max\ E\Big[\int_{t_0}^{\infty} e^{-r(t-t_0)}y\, dt \Big]\\
&amp;= \max\bigg\{ E\Big[\int_{t_0}^{t_0+Δt} e^{-r(t-t_0)}y\, dt \Big] + E\Big[\int_{t_0+Δt}^{\infty} e^{-r(t-t_0)}y\, dt \Big]\bigg\} \\
&amp;= \max\bigg\{ E\Big[\int_{t_0}^{t_0+Δt} e^{-r(t-t_0)}y\, dt \Big] + e^{-rΔt}E\Big[\int_{t_0+Δt}^{\infty} e^{-r(t-t_0-Δt)}y\, dt \Big]\bigg\} \\
&amp;= \max\bigg\{ E\Big[\int_{t_0}^{t_0+Δt} e^{-r(t-t_0)}y\, dt \Big] + e^{-rΔt}E\big[ v(t_0+Δt,x_0+Δx)\big]\bigg\} \end{aligned}\]</span>
subtract <span class="math inline">\(v(t_0,x_0)\)</span> from both sides
<span class="math display">\[0 = \max\bigg\{ E\Big[\int_{t_0}^{t_0+Δt} e^{-r(t-t_0)}y\, dt \Big] + e^{-rΔt}E\big[ v(t_0+Δt,x_0+Δx)\big] - v(t_0,x_0)\bigg\}\]</span>
divide by <span class="math inline">\(Δt\)</span>, let <span class="math inline">\(Δt\to 0\)</span> (<span class="math inline">\(\approx\)</span> differentiation)
<span class="math display">\[\begin{aligned}0 &amp;= \max\bigg\{ E\Big[\frac{1}{Δt}\int_{t_0}^{t_0+Δt} e^{-r(t-t_0)}y\, dt \Big] + \frac{1}{Δt}\underbrace{e^{-rΔt}E\big[ v(t_0+Δt,x_0+Δx)\big]}_{\text{Chain rule}} - \frac{1}{Δt}v(t_0,x_0) \bigg\}\\
&amp;\to\max\bigg\{ y\big(t_0,x(t_0),u(t_0)\big)- rv(t_0,x_0) + \frac{1}{dt}E\big[ dv\ |\ t_0,x_0,u(t_0)\big]\bigg\} \end{aligned}\]</span>
replacing <span class="math inline">\(t_0,x_0\)</span> by <span class="math inline">\(t,x\)</span>,
<span class="math display">\[\begin{aligned}0 &amp;= \max\bigg\{ y\big(t,x,u\big)- rv(t,x) + \frac{1}{dt}E\big[ dv\ |\ t,x,u\big]\bigg\} \\
rv(t,x) &amp;= \max_{u\in U}\bigg\{ y(t,x,u) + \frac{1}{dt}E\big[ dv\ |\ t,x,u\big]\bigg\}\end{aligned}\]</span>
<span class="math inline">\(\implies\)</span> arbitrage condition<br />
LHS: fair rate of return (should equal to)<br />
RHS: current divident + expected capital gain<br />
by Ito’s lemma,
<span class="math display">\[\begin{aligned}E\big[ dv\ |\ t,x,u\big] &amp;=\big\{ v_t(t,x)+a(t,x,u)\cdot v_x(t,x) + \frac{1}{2}b(t,x,u)^2\cdot v_{xx}\big\}\, dt \\
\frac{1}{dt}E\big[ dv\ |\ t,x,u\big] &amp;= v_t(t,x)+a(t,x,u)\cdot v_x(t,x) + \frac{1}{2}b(t,x,u)^2\cdot v_{xx} \end{aligned}\]</span>
<span class="math inline">\(\implies\)</span> Hamilton-Jacobi-Bellman (HJB) equation:
<span class="math display">\[\begin{aligned}rv(t,x) &amp;= \max_{u\in U}\bigg\{ y(t,x,u) + v_t(t,x)+a(t,x,u)\cdot v_x(t,x) + \frac{1}{2}b(t,x,u)^2\cdot v_{xx}\bigg\} \end{aligned}\]</span></li>
</ul>
</div>
<div id="binary-case-optimal-stopping" class="section level3">
<h3>Binary Case: Optimal Stopping</h3>
<ul>
<li>At each period, choose <span class="math inline">\(U=\)</span> { stop, continue }
<span class="math display">\[rv(t,x) = \max_{u\in U}\big\{rω(t,x), y(t,x) + \frac{1}{dt}E[dv\ |\ t,x]\big\}\]</span></li>
</ul>
</div>
<div id="example-irreversible-investment-under-uncertainty" class="section level3">
<h3>Example: Irreversible Investment Under Uncertainty</h3>
<p><a href="http://leonardo3.dse.univr.it/safe/Workshops/PhD/2003/McDonaldSiegel86.pdf">McDonald &amp; Siegel (1986)</a>, <a href="https://watermark.silverchair.com/101-4-707.pdf">backup link</a><br />
<a href="http://93.174.95.27/book/index.php?md5=E5C252386E127800AA284F01CF5B4F41">Dixit &amp; Pindyck (1994)</a></p>
<ul>
<li>Investment: <span class="math inline">\(I\)</span>
<ul>
<li>Sunk cost payable in return for a project of net present value <span class="math inline">\(x\)</span></li>
</ul></li>
<li>Stopping payoff: <span class="math inline">\(ω(x) = x-I\)</span></li>
<li><span class="math inline">\(x\)</span> follows Brownian motion
<ul>
<li><span class="math inline">\(dx = αx\, dt+σx\, dz\)</span></li>
<li><span class="math inline">\(E[x_t] = x_0\cdot e^{αt}\)</span></li>
</ul></li>
<li>Interest rate: <span class="math inline">\(r\)</span></li>
<li>Value of investment opportunity if current value is <span class="math inline">\(x\)</span>
<span class="math display">\[v(x) = \sup_{T\geq 0} \ E\big[e^{-rT}(x_T - I)\ |\ x_0=x \big]\]</span></li>
<li>Assumption: <span class="math inline">\(α&lt;r\)</span> (otherwise wait forever)</li>
<li>Continuation region: by Ito’s lemma, 2nd ODE:
<span class="math display">\[\begin{aligned}rv &amp;= \frac{E[dv]}{dt}\\&amp;= αxv&#39; + \frac{1}{2}σ^2x^2v&#39;&#39;\\
0 &amp;\overset{!}{=} \frac{1}{2}σ^2x^2v&#39;&#39; + αxv&#39; - rv \end{aligned}\]</span>
Guess solution:
<span class="math display">\[\begin{aligned}v(x) &amp;= A\cdot x^β \\
v&#39; &amp;= Aβx^{β-1} \\
v&#39;&#39; &amp;= Aβ(β-1)x^{β-2} \end{aligned}\]</span>
plug back in
<span class="math display">\[\begin{aligned}\frac{1}{2}σ^2x^2\cdot Aβ(β-1)x^{β-2} + αx\cdot Aβx^{β-1} - r\cdot A\cdot x^β &amp;= 0\\
Q(β) := \frac{1}{2}σ^2\cdot Aβ(β-1) + α\cdot Aβ - r\cdot A &amp;= 0\end{aligned}\]</span>
since <span class="math inline">\(Q(0)=-r&lt;0\)</span>, <span class="math inline">\(Q(1)=α-r&lt;0\)</span><br />
<span class="math inline">\(\implies β_1&gt;1\)</span> and <span class="math inline">\(β_2&lt;0\)</span><br />
Therefore, the general solution for the 2nd ODE:
<span class="math display">\[v(x) = A_1 x^{β_1} + A_2 x^{β_2}\]</span>
Since <span class="math inline">\(A_2 x^{β_2}\to\pm\infty\)</span> as <span class="math inline">\(x\to 0\)</span><br />
we know <span class="math inline">\(v(0) = 0\implies A_2=0\)</span><br />
</li>
<li>Value matching
<span class="math display">\[\begin{aligned}v(x) &amp;= A_1 x^{β_1} \\
v(x^*) &amp;= ω(x^*) = x^* - I \\
A_1 (x^*)^{β_1} &amp;= x^* - I \\
A_1 &amp;= \frac{x^* - I}{(x^*)^{β_1}} \end{aligned}\]</span></li>
<li>Smooth pasting
<span class="math display">\[\begin{aligned}v&#39;(x^*) &amp;= ω&#39;(x^*) = 1 \\
A_1β_1(x^*)^{β_1-1} &amp;= 1 \\
A_1β_1(x^*)^{β_1} &amp;= x^* \\
\frac{x^* - I}{(x^*)^{β_1}}\cdot β_1(x^*)^{β_1} &amp;= x^* \\
(x^* - I)β_1 &amp;= x^* \\
x^* &amp;= \frac{Iβ_1}{β_1 - 1} &gt; I\end{aligned}\]</span></li>
</ul>
</div>
<div id="poisson-process" class="section level3">
<h3>Poisson Process</h3>
<ul>
<li>Poisson process: <span class="math inline">\(N_t\)</span>, <span class="math inline">\(t\geq 0\)</span> with intensity <span class="math inline">\(λ&gt;0\)</span></li>
<li><span class="math inline">\(N_t\in\{0,1,2,3,\dots\}\)</span> for all <span class="math inline">\(t\)</span></li>
<li>Sample path are right-continuous (continuous from right) with left limits</li>
<li><span class="math inline">\(N_t-N_s\)</span> is independent of the path up to <span class="math inline">\(s\)</span> for all <span class="math inline">\(t&gt;s\)</span><br />
and has a Poisson distribution with <span class="math inline">\(λ(t-s)\)</span>, i.e.
<span class="math display">\[Pr(N_t-N_s=k)=e^{λ(t-s)}\cdot\frac{[λ(t-s)]^k}{k!}\]</span></li>
<li>On average <span class="math inline">\(λ\)</span> jumps in an interval
<span class="math display">\[\begin{aligned}E[N_t-N_s\ |\ N_s] = λ(t-s) \end{aligned}\]</span></li>
</ul>
</div>
<div id="optimal-exploration-in-two-armed-bandit-problem" class="section level3">
<h3>Optimal Exploration in Two-Armed Bandit Problem</h3>
<p><a href="https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1468-0262.2005.00564.x">Keller, Rady, Cripps (2005)</a></p>
<ul>
<li>Two arms (actions): R(isky), S(afe)</li>
<li>Continuous time: <span class="math inline">\(t\geq 0\)</span></li>
<li>Payoff of S: <span class="math inline">\(s\)</span> per unit of time</li>
<li>Payoff of R: <span class="math inline">\(μ_θ\)</span>
<ul>
<li>Unknown state of the world: <span class="math inline">\(θ\)</span></li>
<li>Known probability: <span class="math inline">\(Pr(θ=1)=p\)</span></li>
<li>Simple case: <span class="math inline">\(θ\in\{0,1\}\)</span>, <span class="math inline">\(\begin{cases}μ_0&lt;s \\ μ_1&gt;s \end{cases}\)</span><br />
</li>
</ul></li>
<li>Wiener process w/ unknown drift: <span class="math display">\[π(R) = μ_θ\cdot t+ z\, dz\]</span>
<ul>
<li><span class="math inline">\(λ_0&lt;s&lt;λ_1\)</span></li>
<li>Prior belief: <span class="math inline">\(p\)</span></li>
<li>Posterior belief: <span class="math inline">\(p_t\)</span> (diffusion)</li>
</ul></li>
<li>Poisson process w/ unknown perameter: <span class="math display">\[π(R) = h\cdot N_t^θ\]</span>
<ul>
<li>Average lump-sum payoff: <span class="math inline">\(h\)</span></li>
<li><span class="math inline">\(0\leq λ_0 &lt; λ_1\)</span><br />
Conclusive news: <span class="math inline">\(λ_0=0\)</span><br />
Inconclusive news: <span class="math inline">\(λ_0\geq 0\)</span></li>
<li>Expected payoff: <span class="math inline">\(λ_θh = μ_θ\)</span></li>
<li>Assumption: <span class="math inline">\(λ_0h&lt;s&lt;λ_1h\)</span></li>
<li>Prior belief: <span class="math inline">\(p\)</span></li>
</ul></li>
</ul>
<blockquote>
<p>Suppose <span class="math inline">\(λ_0=0\)</span>, <span class="math inline">\(λ_1=λ\)</span>,<br />
The agent have used R up to time <span class="math inline">\(t\)</span> w/o a “breakthrough”</p>
</blockquote>
<p>Posterior (Bayesian) belief:
<span class="math display">\[\begin{aligned}p_t &amp;=\frac{Pr(θ=1 \text{ and no success})}{Pr(\text{no success})}\\
&amp;= Pr(θ=1\ |\ \text{no success up to }t) \\
&amp;= \frac{p\cdot e^{-λt}}{p\cdot e^{-λt} + (1-p)}\\
\bar{p}_t &amp;= \frac{dp_t}{dt}\\ &amp;= -λ\cdot p_t(1-p_t) \end{aligned}\]</span>
Optimal strategy: play S for <span class="math inline">\(p_t\leq p^*\)</span><br />
Continuation region: play R (<span class="math inline">\(k=1\)</span>):
<span class="math display">\[rv = rpλh + \frac{E[dv]}{dt}\]</span> <!-- corrected -->
with <span class="math inline">\(Pr=e^{-λdt}=1-λdt\)</span>, no jump, <span class="math inline">\(p_{t+dt} = p-λp(1-p)\, dt\)</span><br />
with <span class="math inline">\(Pr=1-e^{-λdt}=λdt\)</span>, jump, <span class="math inline">\(p_{t+dt} =1\)</span><br />
therefore, by Ito’s Lemma, effect of marginal change in belief result in marginal change in value function:
<span class="math display">\[\begin{aligned}dp &amp;= -λp(1-p)\, dt \\
dv &amp;= (1-λdt)\cdot v&#39;[-λp(1-p)]\, dt + (λdt)\cdot[v(1)-v(p)]\\
&amp;= \big\{-λp(1-p)v&#39; + λ[v(1)-v(p)]\big\}\, dt + \text{some higher order terms} \\
rv &amp;= -λp(1-p)v&#39; + λp[v(1) - v(p)] + rpλh\end{aligned}\]</span> <!-- corrected -->
where <span class="math inline">\(v(1)\)</span> is the payoff when the agent is sure that R is good (?)<br />
Value function:
<span class="math display">\[\begin{aligned}v(p) &amp;= \max\ E\bigg[\int_0^{\infty}\big\{\underbrace{\overbrace{r}e^{-rt}}_{\text{discount}}\cdot k_t λ_t h + (1-k_t)s\big\}\, dt\bigg] \end{aligned}\]</span>
where <span class="math inline">\(k_t=1\)</span> means play R, <span class="math inline">\(k_t=0\)</span> means play S<br />
and <span class="math inline">\(re^{-rt}\)</span> is discounting since <span class="math inline">\(\int re^{-rt}\, dt =1\)</span><br />
<span class="math inline">\(\implies v(1) = λh\)</span><br />
Let <span class="math inline">\(μ=\frac{r}{λ}\)</span>, <span class="math inline">\(g=λh\)</span><br />
<span class="math display">\[\begin{aligned}rv &amp;= -λp(1-p)v&#39; + λp[g - v] + rp\underbrace{λh} \\
μv &amp;= -p(1-p)v&#39; + p[g - v] + μpg \\
p(1-p)v&#39; + (μ+p)v &amp;= (μ+1)pg &amp;&amp; (ODE)\end{aligned}\]</span>
particular solution: <span class="math inline">\(v_1=pg\)</span>, <span class="math inline">\(v_1&#39; = g\)</span> (expected value of playing R forever)<br />
homogeneous equation:
<span class="math display">\[p(1-p)v&#39; + (μ+p)v = 0\]</span>
by seperation of variables,
<span class="math display">\[v_0 = (1-p)(\frac{1-p}{p})^μ\]</span>
therefore, the general solution of the ODE:
<span class="math display">\[v=v_1 + C\cdot v_0\]</span>
Value matching: <span class="math inline">\(v(p^*) = s\)</span>
Smooth pasting: <span class="math inline">\(v&#39;(p^*) =0\)</span>
plug back into ODE,
<span class="math display">\[\begin{aligned}(μ+p^*)s &amp;= (μ+1)p^*g \\
p^* &amp;= \frac{μs}{(μ+1)(g-s)+μs} \end{aligned}\]</span>
Comparative statics: <span class="math inline">\(r\uparrow\)</span> or <span class="math inline">\(λ\downarrow\implies μ\uparrow\)</span> <span class="math inline">\(\implies p^*\uparrow\)</span></p>
</div>
</div>
<div id="presentation-term-paper" class="section level2">
<h2>Presentation &amp; Term Paper</h2>
<ul>
<li>30 min keynote (Jan 13 ~ 31)
<ul>
<li>Real world motivation</li>
<li>Explan the model mathematically</li>
<li>Precise result</li>
<li>Intuition</li>
<li>Own words!!</li>
</ul></li>
<li>15 min Q&amp;A session</li>
<li>8-10 pages (~ Mar 1)
<ul>
<li>(including reference, excluding graphs)</li>
<li>Introduction: how does this study fit into the research body</li>
<li>Motivation</li>
<li>Summrise the model</li>
<li>Key results, intuition</li>
<li>Less details!</li>
<li>Conclusion: did what, learnt what, link back to motivation</li>
</ul></li>
<li>Own contribution: criticise the model
<ul>
<li>Assumptions, what if changed?</li>
<li>Trade-offs, what else?</li>
<li>Real world prediction? Impact?</li>
<li>Extend the model</li>
</ul></li>
<li>Preparation (~ Nov 22)
<ul>
<li>Read the paper</li>
<li>Read the paper with a pen</li>
<li>Read the paper with Google Scholar</li>
<li>Focus on the key research question</li>
</ul></li>
</ul>
<div id="besanko-tong-wu-2018" class="section level3">
<h3>Besanko Tong Wu 2018</h3>
<ul>
<li>Subsidising research</li>
<li>Private <span class="math inline">\(λ\)</span></li>
<li>Maxmin the result</li>
</ul>
</div>
<div id="bonatti-hoerner-2011" class="section level3">
<h3>Bonatti Hoerner 2011</h3>
<ul>
<li>Moral hazard in research teams</li>
</ul>
</div>
<div id="branco-sun-villas-boas-2012" class="section level3">
<h3>Branco Sun Villas-Boas 2012</h3>
<ul>
<li>Optimal stopping for researching for purchasing decision</li>
</ul>
</div>
<div id="che-hoerner-2018" class="section level3">
<h3>Che Hoerner 2018</h3>
<ul>
<li>Spam vs tell everything to the consumer w/ recommender system</li>
</ul>
</div>
<div id="halac-kartik-liu-2016" class="section level3">
<h3>Halac Kartik Liu 2016</h3>
<ul>
<li>Principal hiring agent for research</li>
<li>Adverse selection, moral hazard &amp; private learning</li>
</ul>
</div>
<div id="manso-2011" class="section level3">
<h3>Manso 2011</h3>
<ul>
<li>Subsidising research for 2 period</li>
</ul>
</div>
<div id="strulovici-2010" class="section level3">
<h3>Strulovici 2010</h3>
<ul>
<li>Collective learning</li>
</ul>
</div>
</div>
<div id="kremer-mansour-perry-2014-my-bit" class="section level2">
<h2>Kremer Mansour Perry 2014 (My Bit)</h2>
<ul>
<li>Social planning on recommender system</li>
</ul>
<div id="motivation" class="section level3">
<h3>Motivation</h3>
<ul>
<li>Online platform of recommendation: restaurant, hotels, …
<ul>
<li>Navigation</li>
</ul></li>
<li>Principle: app company
<ul>
<li>relies on users to gather info (explore)</li>
<li>generates recommendation (exploit)</li>
</ul></li>
<li>Agents: app users
<ul>
<li>does not want to gather info (explore)</li>
<li>want to freeride on the recommendation (exploit)</li>
</ul></li>
<li><span class="math inline">\(\implies\)</span> conflict!</li>
</ul>
</div>
<div id="model" class="section level3">
<h3>Model</h3>
<ul>
<li>Set of possible actions: <span class="math inline">\(A=\{a_1,a_2\}\)</span></li>
<li>Unknown reward of <span class="math inline">\(a_i\)</span>: <span class="math inline">\(R_i\sim π_i\)</span>
<ul>
<li><span class="math inline">\(π\)</span> has full support: all values have positive probability</li>
<li>Expected value: <span class="math inline">\(μ_i= E_{R_i\sim π_i}[R_i]\)</span></li>
<li><span class="math inline">\(μ_1&gt;μ_2\)</span> but <span class="math inline">\(Pr(R_1&lt;μ_2)&gt;0\)</span></li>
</ul></li>
<li>Principle
<ul>
<li>Goal: max social welfare <span class="math inline">\(\max \ E\big[\frac{1}{T}\sum R^t\big]\)</span></li>
<li>Message: <span class="math inline">\(\{\tilde{M}^1,\tilde{M}^2,\dots,\tilde{M}^T\}\)</span></li>
</ul></li>
<li>Agents
<ul>
<li>Arrives sequentially, and knows their place in line</li>
<li>Goal: <span class="math inline">\(\max \ E[R^t\ |\ M^t]\)</span></li>
<li>Strategy: <span class="math inline">\(σ^t: M^t\to A\)</span></li>
</ul></li>
<li>Timing: <span class="math inline">\(t\in T\)</span>
<ol style="list-style-type: decimal">
<li>Agent <span class="math inline">\(t\)</span> arrives</li>
<li>Chooses action <span class="math inline">\(a^t\)</span></li>
<li><span class="math inline">\(R_{a^t}\)</span> is realised</li>
<li>Agent <span class="math inline">\(t+1\)</span> arrives</li>
</ol></li>
</ul>
</div>
<div id="result" class="section level3">
<h3>Result</h3>
</div>
<div id="intuition" class="section level3">
<h3>Intuition</h3>
<ul>
<li>(P992) As the # of agents increases, the social welfare converges to 1st best welfare</li>
</ul>
</div>
<div id="my-thoughts" class="section level3">
<h3>My thoughts</h3>
</div>
</div>

    </div>
  </article>
  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  (function() { 
  var d = document, s = d.createElement('script');
  s.src = 'https://loikein-github.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>

</main>
      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>

          <li>By loikein with love</li>
        </ul>
      </footer>
    </div>
    
    <script src="https://hypothes.is/embed.js" async></script>
    
    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-143089736-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>