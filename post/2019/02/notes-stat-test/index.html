<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.62.0" />

<title>Notes on Econometrics - Tests and Statistics - loikein&#39;s notes</title>
<meta property="og:title" content="Notes on Econometrics - Tests and Statistics - loikein&#39;s notes">


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-143089736-1', 'auto');
  
  ga('send', 'pageview');
}
</script>


  


<link rel="icon" type="image/x-icon" href="/favicon.ico" />




<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />


<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">
<link rel="stylesheet" href="/css/clumsy-toc.css" media="all">




  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/post/" class="nav-logo">
    <img src="/images/loikein-logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>
  <ul class="nav-links">
    
    <li><a href="/post/">Posts</a></li>
    
    <li><a href="/tags/">Tags</a></li>
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/loikein/loikein.github.io">GitHub</a></li>
    
  </ul>
</nav>
      </header>
<main class="content" role="main">
  <article class="article">
    
    <span class="article-duration">10 min read</span>
    
    <h1 class="article-title">Notes on Econometrics - Tests and Statistics</h1>
    
    <span class="article-date">2019/02/05</span>
    
    
    
    <span class="tags">
    
    
    Tags:
    
    <a href='/tags/notes'>notes</a>
    
    <a href='/tags/r'>R</a>
    
    <a href='/tags/stat'>stat</a>
    
    
    
    </span>
    
    <div class="article-content">
      

<div id="TOC">
<ul>
<li><a href="#r2">R^2</a></li>
<li><a href="#t-test">t-test</a></li>
<li><a href="#f-test-joint-test-model-test">F-test (Joint Test / Model Test)</a></li>
<li><a href="#wald-test">Wald Test</a><ul>
<li><a href="#wald-statistic">Wald statistic</a></li>
<li><a href="#f-statistic">F-statistic</a></li>
</ul></li>
<li><a href="#bic-aic">BIC &amp; AIC</a><ul>
<li><a href="#nested-model">Nested Model</a></li>
<li><a href="#time-series">Time Series</a></li>
</ul></li>
<li><a href="#j-test-non-nested-model">J Test (Non-Nested Model)</a></li>
<li><a href="#pe-test-linear-vs-log">PE Test (Linear vs Log)</a></li>
<li><a href="#chow-breakpoint-test">Chow (Breakpoint) Test</a></li>
<li><a href="#heteroskedasticity-test">Heteroskedasticity Test</a><ul>
<li><a href="#goldfeld-quandt">Goldfeld-Quandt</a></li>
<li><a href="#breusch-pagan-test">Breusch-Pagan Test</a></li>
</ul></li>
<li><a href="#autocorrelation-test">Autocorrelation Test</a><ul>
<li><a href="#durbin-watson">Durbin-Watson</a></li>
<li><a href="#breusch-godfrey">Breusch-Godfrey</a></li>
<li><a href="#box-pierce">Box-Pierce</a></li>
</ul></li>
<li><a href="#instrumental-variable-test">Instrumental Variable Test</a><ul>
<li><a href="#durbin-wu-hausman-endogeneity">Durbin-Wu-Hausman (Endogeneity)</a></li>
<li><a href="#sargan-instrument-validity">Sargan (Instrument Validity)</a></li>
</ul></li>
<li><a href="#df-dickey-fuller-test">DF (Dickey-Fuller) Test</a><ul>
<li><a href="#unit-root">Unit Root</a></li>
<li><a href="#deterministic-trend">Deterministic Trend</a></li>
<li><a href="#adf-augmented-dickey-fuller-test">ADF (Augmented Dickey-Fuller) Test</a></li>
<li><a href="#spurious-regression-vs-cointegration">Spurious Regression vs Cointegration</a></li>
</ul></li>
<li><a href="#ljungbox-portmanteau-test-residual-analysis">Ljung–Box (Portmanteau) Test (Residual Analysis)</a></li>
<li><a href="#hausman-test-fe-vs-re">Hausman Test (FE vs RE)</a></li>
<li><a href="#read-regression-table">Read Regression Table</a></li>
</ul>
</div>

<p>Warning: under proofreading</p>
<p>Textbook: <a href="http://93.174.95.27/book/index.php?md5=744048ECF4C4A865F45A5877AA7C2BD5">A Guide to Modern Econometrics</a></p>
<div id="r2" class="section level2">
<h2>R^2</h2>
<p>textbook P21, slide 3 P4</p>
<ul>
<li>Proportion of the sample variance of <span class="math inline">\(y\)</span> that is explained by the model.</li>
</ul>
<p><span class="math display">\[\begin{aligned}  &amp;&amp; R^2 &amp;= \frac{Var(\hat{y}_i)}{Var(y_i)} = 1 - \frac{Var(e_i)}{Var(y_i)} \\
&amp;&amp; &amp;= 1 - \frac{\sum_N e_i^2}{\sum_N (y_i-\bar{y})^2} \\
\text{adjusted:} &amp;&amp; \bar{R^2} &amp;= 1 - \frac{\frac{1}{N-K}\sum_N  e_i^2}{\frac{1}{N-1}\sum_N  (y_i-\bar{y})^2}\end{aligned}\]</span></p>
<blockquote>
<p>PS2.Q1<br />
Consider two linear regression models:<br />
<span class="math display">\[\begin{aligned} y &amp;= X_1 b_{11} + e_1 \\
y &amp;= X_1 b_{21} + X_2 b_{22} + e_2\end{aligned}\]</span>
The solution to the minimization problem of the first model is given by <span class="math inline">\(b_{11}\)</span> and for the second model by <span class="math inline">\(b_{21}\)</span> for the regressors in <span class="math inline">\(X_1\)</span> and <span class="math inline">\(b_{22}\)</span> for the regressors in <span class="math inline">\(X_2\)</span>.<br />
<span class="math inline">\(e_1\)</span> and <span class="math inline">\(e_2\)</span> denote the residuals.<br />
Denote the <span class="math inline">\(R^2\)</span> for the first model by <span class="math inline">\(R^2_1\)</span> and for the second model by <span class="math inline">\(R^2_2\)</span>.<br />
Show that <span class="math inline">\(R^2_2 ≥ R^2_1\)</span> (<span class="math inline">\(R^2\)</span> always increases if we increase the number of regressors in models with intercept)</p>
</blockquote>
<p>According to the models,<br />
<span class="math display">\[\begin{aligned} R^2_1 &amp;= 1- \frac{e_1&#39;e_1}{\sum_{i=1}^N (y_i - \bar{y})^2} \\
R^2_2 &amp;= 1- \frac{e_2&#39;e_2}{\sum_{i=1}^N (y_i - \bar{y})^2}\end{aligned}\]</span>
Note for model 2, <span class="math inline">\(b_{21}\)</span> and <span class="math inline">\(b_{22}\)</span> are s.t.<br />
<span class="math display">\[S(\mathbf{\tilde{b_2}}) = \sum^N_{i=1} (y_i - x_i&#39; \mathbf{\tilde{b_2}})\]</span>
is minimized. Therefore,<br />
<span class="math display">\[\begin{aligned} \sum^N_{i=1} \big(y_i - x_i&#39; (b_{21},b_{22})&#39; \big) &amp;\leq \sum^N_{i=1} \big(y_i - x_i&#39; (b_{1}, 0)&#39; \big) \\
e_2&#39;e_2 &amp;\leq e_1&#39;e_1 \\ 
R^2_2 &amp;\geq R^2_1 \end{aligned}\]</span></p>
</div>
<div id="t-test" class="section level2">
<h2>t-test</h2>
<p>textbook P26, slide 3 P16</p>
<ul>
<li><a href="../../01/notes-stat1-theory/#normality-of-b">Normality of b</a></li>
<li><span class="math inline">\(H_0\)</span>: <span class="math inline">\(b_k = β^0_k\)</span></li>
<li><span class="math inline">\(H_0\)</span> is rejected if <span class="math inline">\(t_k\)</span> is significantly different to some critical value <span class="math inline">\(\begin{cases}\text{one-sided} &amp; t_{N-K; α} \\ \text{two-sided} &amp; t_{N-K; α/2} \end{cases}\)</span></li>
</ul>
<p><span class="math display">\[\begin{aligned} z &amp;= \frac{b_k - β_k}{se(b_k)} ∼ \mathcal{N}(0,1) \\
t_k &amp;= \frac{b_k - β^0_k}{se(b_k)} \end{aligned}\]</span></p>
<p><span class="math inline">\(t ∼ t_{N-K} ∼^a \mathcal{N}(0,1)\)</span><br />
<span class="math inline">\(N\)</span> is the number of observations, <span class="math inline">\(K\)</span> is the number of <span class="math inline">\(β\)</span> 's.</p>
<blockquote>
<p>PS4.Q2.9<br />
T/F?<br />
When testing multiple restrictions, a t-test cannot be used.</p>
</blockquote>
<p>True.</p>
<blockquote>
<p>PS4.Q2.8<br />
T/F?<br />
When testing a single restriction, a t-test must be used as an F-test cannot be computed for <span class="math inline">\(J = 1\)</span>.</p>
</blockquote>
<p>False.<br />
When testing a single restriction, F-test is equivalent to t-test squared.<br />
Check this complete proof by <a href="https://jmcanovas.netlify.com/2018/10/29/when-does-the-f-test-reduce-to-t-test/">Juan Manuel</a>.</p>
</div>
<div id="f-test-joint-test-model-test" class="section level2">
<h2>F-test (Joint Test / Model Test)</h2>
<p>textbook P26, P70, slide 3 P18</p>
<p><span class="math display">\[\begin{aligned}\text{Unrestricted Model: } y_1 &amp;= β_1 + β_2x_2 + \dots + β_K x_K + ε \\
\text{Restricted Model: } y_0 &amp;= β_1 + β_2x_2 + \dots + β_{K-J}x_{K-J} + ε\end{aligned}\]</span></p>
<p><span class="math display">\[\begin{aligned} F &amp;= \frac{(S_0 - S_1) / J}{S_1 / (N-K)} \\
&amp;= \frac{(R^2_1 - R^2_0) / J}{(1-R^2_1) / (N-K)}\end{aligned}\]</span></p>
<p><span class="math inline">\(H_0\)</span>: <span class="math inline">\(β_{K-J+1} = β_{K-J+2} = \dots = β_K = 0\)</span>,<br />
<span class="math inline">\(F ∼ F_{N-K}^J\)</span><br />
<span class="math inline">\(N\)</span> is the number of observations, <span class="math inline">\(K\)</span> is the number of <span class="math inline">\(β\)</span> 's, and <span class="math inline">\(J\)</span> is the number of <span class="math inline">\(β\)</span> 's to be tested (<span class="math inline">\(= 0\)</span>), <span class="math inline">\(F \geq J + 1\)</span>.</p>
</div>
<div id="wald-test" class="section level2">
<h2>Wald Test</h2>
<p>textbook P29, P103 (GLS), slide 3 P17</p>
<ul>
<li>Always two-sided</li>
<li>Set of J Restrictions: <span class="math inline">\(\underbrace{R}_{\text{(J*K)}}\underbrace{β}_{\text{(K*1)}} = \underbrace{q}_{\text{(J*1)}}\)</span></li>
</ul>
<div id="wald-statistic" class="section level3">
<h3>Wald statistic</h3>
<ul>
<li>Gauss-Markov Assumptions are not all satisfied</li>
<li>The model deviates from linear regression model</li>
</ul>
<p><span class="math display">\[\begin{aligned} ξ &amp;= (Rb - q)&#39; \big[R\cdot V(b) R&#39; \big]^{-1}(Rb - q) \\
&amp;= \frac{1}{s^2} (Rb - q)&#39; \big[R(X&#39; X)^{-1} R&#39; \big]^{-1}(Rb - q)\end{aligned}\]</span>
<span class="math inline">\(H_0: ξ ∼ Χ^2_J\)</span><br />
<span class="math inline">\(K\)</span> is the number of <span class="math inline">\(β\)</span> 's, <span class="math inline">\(J\)</span> is the number of <span class="math inline">\(β\)</span> 's to be tested, <span class="math inline">\(R\)</span> is a <span class="math inline">\(J\times K\)</span> matrix, <span class="math inline">\(Rβ - q = 0\)</span>.</p>
</div>
<div id="f-statistic" class="section level3">
<h3>F-statistic</h3>
<ul>
<li>Exact sampling distribution under (A1) ~ (A5)</li>
</ul>
<p><span class="math display">\[F = \frac{ξ}{J} = \frac{1}{J \cdot s^2} (Rb - q)&#39; \big[R(X&#39; X)^{-1} R&#39; \big]^{-1}(Rb - q)\]</span>
<span class="math inline">\(H_0: F ∼ F^J_{N-K}\)</span></p>
<blockquote>
<p>PS3.Q1.2<br />
For model <span class="math inline">\(\log{Y_t} = \log τ + β_1\log K_t + β_2\log L_t (+ ε_t)\)</span>, consider the regression output:<br />
<img src="/post-img/notes-stat1--PS3Q1.png" width="406" /><br />
<span class="math inline">\((X&#39; X)^{-1} = \begin{pmatrix} 5649.38 &amp;&amp; 307.02 &amp;&amp; \\ &amp;&amp; 16.85 &amp;&amp; -29.39 \\ -540.33 &amp;&amp; &amp;&amp; 51.68\end{pmatrix}\)</span><br />
3. Test the hypothesis of constant returns to scale at <span class="math inline">\(5\%\)</span> level.</p>
</blockquote>
<p>Constant return to scale <span class="math inline">\(\implies β_1 + β_2 = 1\)</span><br />
Let <span class="math inline">\(R = \begin{pmatrix} 0 &amp;&amp; 1 &amp;&amp; 1\end{pmatrix}\)</span>, <span class="math inline">\(β = \begin{pmatrix} \log τ \\ β_1 \\ β_2 \end{pmatrix}\)</span>, <span class="math inline">\(q = 1 \implies J = 1\)</span>.<br />
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(Rβ = q\)</span><br />
<span class="math display">\[F = \frac{1}{J \cdot s^2} (Rb - q)&#39; \big[R(X&#39; X)^{-1} R&#39; \big](Rb - q)\]</span>
Since <span class="math inline">\(X&#39;X\)</span> is symmetric, <span class="math inline">\((X&#39; X)^{-1} = \begin{pmatrix} 5649.38 &amp;&amp; 307.02 &amp;&amp; -540.33 \\ 307.02 &amp;&amp; 16.85 &amp;&amp; -29.39 \\ -540.33 &amp;&amp; -29.39 &amp;&amp; 51.68\end{pmatrix}\)</span><br />
Calculate F-statistics:</p>
<pre class="r"><code>matrix_x &lt;- matrix(c(5649.38, 307.02, -540.33, 307.02, 16.85, -29.39, -540.33, -29.39, 51.68), nrow = 3, byrow = TRUE)
matrix_r &lt;- matrix(c(0,1,1), nrow = 1, byrow = TRUE)
matrix_b &lt;- matrix(c(-5.9395, 0.3593, 0.8045), nrow = 3)
scalar_q &lt;- 1

# parts

result_1 &lt;- 1 / 0.0381^2
result_2 &lt;-matrix_r %*% matrix_b - scalar_q
result_3 &lt;- matrix_r %*% matrix_x %*% t(matrix_r)

# calculate F-statistics

result_1 * t(result_2) * result_3^(-1) * result_2
##          [,1]
## [1,] 1.895716</code></pre>
<p>Calculate critical value at <span class="math inline">\(5\%\)</span> level, for one restriction and <span class="math inline">\(df = 40\)</span>:</p>
<pre class="r"><code>qf( 0.95, 1, 40)
## [1] 4.084746</code></pre>
<p>Therefore, <span class="math inline">\(H_0\)</span> is not rejected.</p>
</div>
</div>
<div id="bic-aic" class="section level2">
<h2>BIC &amp; AIC</h2>
<div id="nested-model" class="section level3">
<h3>Nested Model</h3>
<p>(textbook P69, slide 5 P10)<br />
BIC is asymptotically consistent:
<span class="math display">\[\min \ I(K) = \log\left(\frac{e&#39;e}{N}\right) + \log N\cdot\frac{K}{N}\]</span>
<span class="math inline">\(N\)</span> is the number of observations, <span class="math inline">\(K\)</span> is the number of <span class="math inline">\(β\)</span> 's, and <span class="math inline">\(e\)</span> is vector of residual.<br />
If replace <span class="math inline">\(\log N\)</span> with <span class="math inline">\(2\)</span>, becomes AIC (inconsistent for large sample)</p>
</div>
<div id="time-series" class="section level3">
<h3>Time Series</h3>
<p>(textbook P320, slide 12 P25)<br />
<span class="math display">\[\min \ BIC = \log \hat{σ}^2 + \log T \cdot\frac{p+q+1}{T}\]</span>
<span class="math inline">\(p,q\)</span> are the orders of ARMA model, and <span class="math inline">\(T\)</span> is the number of periods<br />
If replace <span class="math inline">\(\log T\)</span> with <span class="math inline">\(2\)</span>, becomes AIC (tend to overparameterize)</p>
</div>
</div>
<div id="j-test-non-nested-model" class="section level2">
<h2>J Test (Non-Nested Model)</h2>
<p>(textbook P72, slide 5 P11)<br />
<span class="math display">\[\begin{aligned} \text{Model A: } y_i &amp;= x_i&#39; β + ε_i \\
\text{Model B: } y_i &amp;= z_i&#39; γ + v_i \\
\text{Test Model: } y_i &amp;= \underbrace{(1-δ)x_i&#39; β}_{\text{Model A}} + \underbrace{δ z_i&#39; γ }_{\text{Model B}} + u_i \\
&amp;=^{H_0} x_i&#39; + δ \hat{y}_{i,B} + u_i \end{aligned}\]</span>
<span class="math inline">\(H_0: \ t_{δ} = \frac{δ}{se(δ)} ∼ t\)</span></p>
</div>
<div id="pe-test-linear-vs-log" class="section level2">
<h2>PE Test (Linear vs Log)</h2>
<p>(textbook P72, slide 5 P13)<br />
<span class="math display">\[\begin{aligned}\text{Linear Model: }&amp;\hat{y_i} = \dots \\ \text{Log Model: }&amp;\log\tilde{y_i} = \dots \end{aligned}\]</span>
<span class="math display">\[\begin{aligned}\text{Test Models: }\phantom{\log} y_i &amp;= x_i&#39; β + δ_{Lin} (\log \underbrace{\hat{y_i}}_{\text{Linear Model}} - \underbrace{\log\tilde{y_i}}_{\text{Log Model}}) + u_i \\
\log y_i &amp;= (\log x_i)&#39; γ + δ_{Log} \big(\overbrace{\hat{y_i}} - \exp(\overbrace{\log\tilde{y_i}})\big) + u_i \end{aligned}\]</span>
<span class="math display">\[\begin{aligned}H_0\text{&#39;s: } &amp;t_{δ_{Lin}} ∼ t \implies\text{linear model is preferred} \\
&amp;t_{δ_{Log}} ∼ t \implies\text{log model is preferred}\end{aligned}\]</span>
If both <span class="math inline">\(H_0\)</span>’s are rejected, should consider more general models.</p>
<blockquote>
<p>PS4.Q2.5<br />
T/F?<br />
The PE test cannot be applied to compare a linear to an exponential specification.</p>
</blockquote>
<p>False.<br />
Just <span class="math inline">\(\log\)</span> both of them.</p>
</div>
<div id="chow-breakpoint-test" class="section level2">
<h2>Chow (Breakpoint) Test</h2>
<p>textbook P75, slide 5 P17</p>
<p><span class="math display">\[\begin{aligned}\text{Pooled Model: } y_i &amp;= x_i&#39; β + g_i x_i&#39; γ + ε_i \\ S_R &amp;= e&#39;e \\
\text{Split Models: } y_i &amp;=  x_i&#39;β_1 + ε_i &amp;&amp; i = 1, \dots, T^* \\
y_i &amp;=  x_i&#39;β_2 + ε_i &amp;&amp; i = T^*+1, \dots, n \\
S_{UR} &amp;= e_1&#39; e_1 + e_2&#39; e_2\end{aligned}\]</span>
<span class="math display">\[H_0: \frac{\frac{1}{K} S_R - S_{UR}}{\frac{1}{N-2K}S_{UR}} ∼ F_{N-2K}^K\]</span>
<span class="math inline">\(N\)</span> is the number of observations, <span class="math inline">\(K\)</span> is the number of <span class="math inline">\(β\)</span> 's, and <span class="math inline">\(T^*\)</span> is the hypothetical breakpoint.<br />
Note: Chow test can also test two or more breakpoints / groups.</p>
<blockquote>
<p>PS4.Q2.6<br />
T/F?<br />
The Chow test cannot be applied in a cross-sectional regression.</p>
</blockquote>
<p>False.<br />
Chow test can also be used to detach groups in a cross-sectional regression.</p>
</div>
<div id="heteroskedasticity-test" class="section level2">
<h2>Heteroskedasticity Test</h2>
<div id="goldfeld-quandt" class="section level3">
<h3>Goldfeld-Quandt</h3>
<p>slide 6 P20</p>
<p>Assume there are two different groups in the observations, <span class="math inline">\(N_A\)</span> and <span class="math inline">\(N_B\)</span><br />
<span class="math display">\[\begin{aligned} GQ = \frac{s_A^2}{s_B^2} ∼F^{N_A-K}_{N_B-K}\end{aligned}\]</span>
<span class="math inline">\(s^2_i = \frac{1}{N_i - K}e&#39;e\)</span> is the unbiased estimator for <span class="math inline">\(σ^2_i\)</span>, and <span class="math inline">\(K\)</span> is the number of <span class="math inline">\(β\)</span> 's.</p>
</div>
<div id="breusch-pagan-test" class="section level3">
<h3>Breusch-Pagan Test</h3>
<p>textbook P109, slide 6 P20</p>
<ul>
<li><a href="../../01/notes-stat1-theory/#wls-weighted-ls-estimator">Assumed form of heteroskedasticity</a></li>
<li>Lagrange multiplier (LM) test
<ul>
<li>No need to estimat restricted model</li>
<li>Auxiliary regression</li>
</ul></li>
</ul>
<p>For <span class="math inline">\(y_i = x_i&#39;β + ε_i\)</span>, and <span class="math inline">\(z_i\)</span> (J-dimensional)<br />
Heteroskedasticity:<br />
<span class="math display">\[\begin{aligned} V\{ε_i | x_i\} &amp;= σ_i^2 \\
&amp;= σ^2\cdot h(z_i \cdot α) \end{aligned}\]</span>
The test:<br />
<span class="math display">\[\begin{aligned}\text{Auxiliary regression} &amp;&amp; e_i^2 &amp;= z_i&#39;α+ v_i\\
\text{Test statistic} &amp;&amp; LM(ξ) &amp;= N\cdot R^2 ∼^a χ^2_J \\
&amp;&amp; H_0: \ α &amp;= 0 \\
&amp;&amp; H_1: \ α &amp;\neq 0\end{aligned}\]</span>
<span class="math inline">\(N\)</span> is the number of observations, <span class="math inline">\(R^2\)</span> is the R-quare of auxiliary regression, and <span class="math inline">\(J\)</span> is the dimension of <span class="math inline">\(z_i\)</span>.</p>
</div>
</div>
<div id="autocorrelation-test" class="section level2">
<h2>Autocorrelation Test</h2>
<div id="durbin-watson" class="section level3">
<h3>Durbin-Watson</h3>
<p>textbook P120, slide 7 P7</p>
<ul>
<li>(A2) all errors and independent variables are independent</li>
<li>Non-zero intercept</li>
<li>No lagged dependent variable (<span class="math inline">\(y_i\)</span>)</li>
</ul>
<p><span class="math display">\[\begin{aligned}dw &amp;= \frac{\sum_N (e_t - e_{t-1})^2}{\sum_N e_t^2} \\
&amp;\approx 2 - 2\hat{ρ} \\
&amp;= 2 - 2\cdot\frac{\sum_N e_te_{t-1}}{\sum_N e_{t-1}^2}\end{aligned}\]</span>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(ρ = 0\iff dw = 2\)</span></p>
</div>
<div id="breusch-godfrey" class="section level3">
<h3>Breusch-Godfrey</h3>
<p>textbook P119, slide 7 P12</p>
<ul>
<li>LM test</li>
</ul>
<p><span class="math display">\[\begin{aligned}\text{Assumed form of error:} &amp;&amp; ε_t &amp;= ρ_1 ε_{t-1} + \dots + ρ_m ε_{t-m} + v_t \\
\text{Auxiliary regression:} &amp;&amp; e_t &amp;= x_t&#39;β + \underbrace{ρ_1 e_{t-1} + \dots + ρ_m e_{t-m}}_{H_0: = 0} + v_t \\
\text{Test statistic:} &amp;&amp; LM &amp;= T\cdot R^2 ∼^a χ_m^2\end{aligned}\]</span></p>
</div>
<div id="box-pierce" class="section level3">
<h3>Box-Pierce</h3>
<p>slide 7 P12</p>
<p><span class="math display">\[Q_m =T\cdot\sum_{j=1}^m \hat{ρ_j}^2\]</span>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(Q_m ∼^a χ^2_m\)</span><br />
<span class="math inline">\(T\)</span> is number of observations, <span class="math inline">\(m\)</span> is number of lags, and <span class="math inline">\(ρ\)</span> 's are parameters.</p>
</div>
</div>
<div id="instrumental-variable-test" class="section level2">
<h2>Instrumental Variable Test</h2>
<div id="durbin-wu-hausman-endogeneity" class="section level3">
<h3>Durbin-Wu-Hausman (Endogeneity)</h3>
<p>textbook P154, slide 9-2 P15</p>
<ul>
<li>Assumption: IV is valid</li>
<li><span class="math inline">\(H_0\)</span>: Both OLS and IV estimators are consistent <span class="math inline">\(\iff γ = 0\)</span></li>
<li><span class="math inline">\(H_1\)</span>: OLS estimators is inconsistent, IV estimators is consistent</li>
</ul>
<p><span class="math display">\[\begin{aligned}\text{Original model:} &amp;&amp; y_i &amp;= β_1x_{1i} + β_2z_{2i} + \underbrace{v_i}_{\text{As error}} \\
\text{Second regression:} &amp;&amp; y_i &amp;= β_1x_{1i} + β_2z_{2i} + \underbrace{γ\cdot v_i}_{\text{As regressor}} + ε_i \\
\text{Test statistic:} &amp;&amp; t &amp;= \frac{γ}{se(γ)} ∼ t\end{aligned}\]</span></p>
</div>
<div id="sargan-instrument-validity" class="section level3">
<h3>Sargan (Instrument Validity)</h3>
<p>textbook P168, slide 9-2 P14</p>
<ul>
<li>Overspecification (<span class="math inline">\(R&gt;K\)</span>)</li>
<li><a href="#give-generalized-iv-estimator">GIVE with optimal weighting matrix</a></li>
<li><span class="math inline">\(H_0\)</span>: instruments are valid (sample moments are close to zero)</li>
</ul>
<p><span class="math display">\[\begin{aligned}\text{Regress with GIVE:} &amp;&amp; y_i &amp;= z_i&#39;\hat{β}_{IV} + \hat{ε}_i \\
\text{Auxiliary regression:} &amp;&amp; \hat{ε}_i &amp;= z_i&#39;\hat{β}_{IV} + v_i \\
\text{Test statistic:} &amp;&amp; LM &amp;= N\cdot R^2 ∼^a χ_{R-K}^2 \\
&amp;&amp; &amp;= N\cdot Q_N(\hat{β}_{IV})\end{aligned}\]</span></p>
</div>
</div>
<div id="df-dickey-fuller-test" class="section level2">
<h2>DF (Dickey-Fuller) Test</h2>
<p>Almost each version has different critical values<br />
DF test and ADF test on the same parameter share the same critical values</p>
<div id="unit-root" class="section level3">
<h3>Unit Root</h3>
<p>(textbook P302, slide 12 P20)<br />
(one-sided)<br />
For AR (1): <span class="math inline">\(Y_t = δ + θY_{t-1} + ε_t\)</span><br />
Or <span class="math inline">\(ΔY_t = δ + \underbrace{(θ-1)}_{π}Y_{t-1} + ε_t\)</span>
<span class="math display">\[DF = \frac{\hat{θ}-1}{se(\hat{θ})}\]</span>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(θ = 1\)</span> or <span class="math inline">\(π = 0\)</span> (does not follow standard t-distribution, needs smaller critical values)<br />
<span class="math inline">\(H_1\)</span>: <span class="math inline">\(θ &lt; 1\)</span> or <span class="math inline">\(π &lt; 0\)</span></p>
</div>
<div id="deterministic-trend" class="section level3">
<h3>Deterministic Trend</h3>
<p>(textbook P303, slide 12 P21)<br />
For AR (1): <span class="math inline">\(ΔY_t = δ + \underbrace{(θ-1)}_{π}Y_{t-1} + γ\cdot t + ε_t\)</span><br />
against random walk: <span class="math inline">\(ΔY_t = δ + ε_t\)</span><br />
<span class="math display">\[DF_τ = \frac{\hat{θ}-1}{se(\hat{θ})}\]</span>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(γ = 0\)</span> (assume satisfied) and <span class="math inline">\(θ-1 = 0\implies θ = 1\)</span> or <span class="math inline">\(π = 0\)</span><br />
<span class="math inline">\(H_1\)</span>: <span class="math inline">\(θ &lt; 1\)</span> or <span class="math inline">\(π &lt; 0\)</span>, include nothing about <span class="math inline">\(γ\)</span></p>
</div>
<div id="adf-augmented-dickey-fuller-test" class="section level3">
<h3>ADF (Augmented Dickey-Fuller) Test</h3>
<p>(textbook P304, slide 12 P23)<br />
For AR (p): <span class="math inline">\(ΔY_t = δ + \underbrace{(θ_1 + θ_2 + \dots + θ_p -1)}_{π}Y_{t-1} + \sum_{i=1}^{p-1} c_i\cdot ΔY_{t-i} (+ γ\cdot t) + ε_t\)</span><br />
where <span class="math inline">\(c_1,\cdots,c_{p-1}\)</span> are constants,<br />
<span class="math display">\[DF_{(τ)} = \frac{\hat{π}}{se(\hat{π})}\]</span>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(π = 0\)</span><br />
<span class="math inline">\(H_1\)</span>: <span class="math inline">\(π &lt; 0\)</span></p>
</div>
<div id="spurious-regression-vs-cointegration" class="section level3">
<h3>Spurious Regression vs Cointegration</h3>
<p>(textbook P354, slide 12 P33)<br />
For <span class="math inline">\(Y_t = α + βX_t + ε_t\)</span>,<br />
<span class="math display">\[\begin{aligned} \text{Auxiliary regression: } Δe_t = γ_0 + γ_1e_{t-1}+u_t \\
\text{Test statistic: } DF = \frac{\hat{γ}_1}{se(\hat{γ}_1)}\end{aligned}\]</span>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(γ_1 = 1\)</span> (unit root)<br />
<span class="math inline">\(H_1\)</span>: <span class="math inline">\(γ_1 &lt; 1\)</span></p>
<p>Use ADF if <span class="math inline">\(e_t\)</span> does not seem to follow AR (1).</p>
</div>
</div>
<div id="ljungbox-portmanteau-test-residual-analysis" class="section level2">
<h2>Ljung–Box (Portmanteau) Test (Residual Analysis)</h2>
<p>(textbook P319, slide 12 P26)<br />
For ARMA (p,q): <span class="math inline">\(Y_t = θ_1Y_{t-1} +\cdots + θ_pY_{t-p} + ε_t + α_1 ε_{t-1} +\cdots + α_q ε_{t-q}\)</span><br />
<span class="math display">\[Q_K = T(T+2)\sum_{k=1}^K \frac{1}{T-k}r_k^2 ∼ χ^2_{(K-p-q)}\]</span>
<span class="math inline">\(H_0\)</span>: residuals are white noise<br />
<span class="math inline">\(T\)</span> is the number of periods, <span class="math inline">\(K &gt; p+q\)</span> is some number chosen by the researcher, and <span class="math inline">\(r_k^2\)</span> is the autocorrelation coefficients of residuals</p>
</div>
<div id="hausman-test-fe-vs-re" class="section level2">
<h2>Hausman Test (FE vs RE)</h2>
<p>(textbook P394, slide 13 P36)<br />
<span class="math display">\[ξ_H = \left(\frac{\hat{β}_{FE} - \hat{β}_{RE}}{\sqrt{Var(\hat{β}_{FE}) - Var(\hat{β}_{RE})}}\right)^2\]</span>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(ξ_H ∼ χ^2_1\)</span> (<span class="math inline">\(\hat{β}_{RE}\)</span> is effecient)</p>
</div>
<div id="read-regression-table" class="section level2">
<h2>Read Regression Table</h2>
<blockquote>
<p>PS3.Q1.2<br />
For model <span class="math inline">\(\log{Y_t} = \log τ + β_1\log K_t + β_2\log L_t (+ ε_t)\)</span>, consider the regression output:<br />
<img src="/post-img/notes-stat1--PS3Q1.png" width="406" /><br />
1. Test the significance of the elasticities at <span class="math inline">\(5\%\)</span> level.</p>
</blockquote>
<p><span class="math inline">\(H_0\)</span>: <span class="math inline">\(β_1 = 0\)</span>, <span class="math inline">\(β_2 = 0\)</span><br />
<span class="math inline">\(H_1\)</span>: <span class="math inline">\(β_1 &gt; 0\)</span>, <span class="math inline">\(β_2 &gt;0\)</span><br />
Calculate critical value at <span class="math inline">\(5\%\)</span> and <span class="math inline">\(1\%\)</span> level, <span class="math inline">\(df = 40\)</span>:</p>
<pre class="r"><code>qt( 0.95, 40 )
## [1] 1.683851
qt( 0.99, 40 )
## [1] 2.423257</code></pre>
<p>Therefore, <span class="math inline">\(K\)</span> is significant at <span class="math inline">\(5\%\)</span> level, and <span class="math inline">\(L\)</span> is significant at <span class="math inline">\(1\%\)</span> level.</p>
<blockquote>
<p>PS3.Q1.2<br />
For model <span class="math inline">\(\log{Y_t} = \log τ + β_1\log K_t + β_2\log L_t (+ ε_t)\)</span>, consider the regression output:<br />
<img src="/post-img/notes-stat1--PS3Q1.png" width="406" /><br />
2. Conduct a test of explanatory power (all coefficients are zero except the intercept).</p>
</blockquote>
<p><span class="math inline">\(H_0\)</span>: <span class="math inline">\(R^2_U = 0\)</span><br />
Calculate critical value at <span class="math inline">\(5\%\)</span> level, for two restrictions and <span class="math inline">\(df = 40\)</span>:</p>
<pre class="r"><code>qf( 0.95, 2, 40)
## [1] 3.231727</code></pre>
<p>As <span class="math inline">\(F = 1936 &gt;\)</span> 3.231727, <span class="math inline">\(H_0\)</span> is rejected.</p>
</div>

    </div>
  </article>
  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  (function() { 
  var d = document, s = d.createElement('script');
  s.src = 'https://loikein-github.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>

</main>
      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>

          <li>By loikein with love</li>
        </ul>
      </footer>
    </div>
    
    <script src="https://hypothes.is/embed.js" async></script>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>


    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-143089736-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>