<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.69.2" />

<title>Notes on Econometrics - Exercises - loikein&#39;s notes</title>
<meta property="og:title" content="Notes on Econometrics - Exercises - loikein&#39;s notes">


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-143089736-1', 'auto');
  
  ga('send', 'pageview');
}
</script>


  


<link rel="icon" type="image/x-icon" href="/favicon.ico" />


<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">
<link rel="stylesheet" href="/css/clumsy-toc.css" media="all">





  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/logo.png"
         width="50"
         height="50"
         alt="Home">
  </a>
  <ul class="nav-links">
    
    <li><a href="/post/">Notes</a></li>
    
    <li><a href="/writings/">Writings</a></li>
    
    <li><a href="/tags/">Tags</a></li>
    
    <li><a href="https://github.com/loikein/loikein.github.io">Source</a></li>
    
  </ul>
</nav>

      </header>
<main class="content" role="main">
  <article class="article">
    
    <span class="article-duration">19 min read</span>
    
    <h1 class="article-title">Notes on Econometrics - Exercises</h1>
    
    <span class="article-date">2019/03/23</span>
    
    
    
    <span class="tags">
    
    
    Tags:
    
    <a href='/tags/notes'>notes</a>
    
    <a href='/tags/stat'>stat</a>
    
    
    
    </span>
    
    <div class="article-content">
      

<div id="TOC">
<ul>
<li><a href="#exercise-2.1-regression">Exercise 2.1 (Regression)</a><ul>
<li><a href="#a">a</a></li>
<li><a href="#b">b</a></li>
<li><a href="#c">c</a></li>
<li><a href="#d">d</a></li>
<li><a href="#e">e</a></li>
<li><a href="#f">f</a></li>
<li><a href="#g">g</a></li>
<li><a href="#h">h</a></li>
<li><a href="#i">i</a></li>
<li><a href="#j">j</a></li>
</ul></li>
<li><a href="#exercise-2.4-regression---true-or-false">Exercise 2.4 (Regression - True or False?)</a><ul>
<li><a href="#a-1">a</a></li>
<li><a href="#b-1">b</a></li>
<li><a href="#c-1">c</a></li>
<li><a href="#d-1">d</a></li>
<li><a href="#e-1">e</a></li>
<li><a href="#f-1">f</a></li>
<li><a href="#g-1">g</a></li>
<li><a href="#h-1">h</a></li>
<li><a href="#i-1">i</a></li>
<li><a href="#j-1">j</a></li>
<li><a href="#k">k</a></li>
<li><a href="#l">l</a></li>
<li><a href="#m">m</a></li>
<li><a href="#n">n</a></li>
</ul></li>
<li><a href="#exercise-3.2-regression---empirical">Exercise 3.2 (Regression - Empirical)</a><ul>
<li><a href="#a-2">a</a></li>
<li><a href="#b-2">b</a></li>
<li><a href="#c-2">c</a></li>
<li><a href="#d-2">d</a></li>
<li><a href="#e-2">e</a></li>
<li><a href="#f-2">f</a></li>
<li><a href="#g-2">g</a></li>
<li><a href="#h-2">h</a></li>
<li><a href="#i-2">i</a></li>
</ul></li>
<li><a href="#exercise-3.4-regression---empirical">Exercise 3.4 (Regression - Empirical)</a></li>
<li><a href="#exercise-5.1-instrumental-variables">Exercise 5.1 (Instrumental Variables)</a><ul>
<li><a href="#a-3">a</a></li>
<li><a href="#b-3">b</a></li>
<li><a href="#c-3">c</a></li>
<li><a href="#d-3">d</a></li>
<li><a href="#e-3">e</a></li>
<li><a href="#f-3">f</a></li>
<li><a href="#g-3">g</a></li>
</ul></li>
<li><a href="#exercise-5.2-returns-to-schooling---empirical">Exercise 5.2 (Returns to Schooling - Empirical)</a></li>
<li><a href="#exercise-7.1-binary-choice-models">Exercise 7.1 (Binary Choice Models)</a><ul>
<li><a href="#a-4">a</a></li>
<li><a href="#b-4">b</a></li>
<li><a href="#c-4">c</a></li>
<li><a href="#d-4">d</a></li>
<li><a href="#e-4">e</a></li>
<li><a href="#f-4">f</a></li>
<li><a href="#g-4">g (*)</a></li>
<li><a href="#h-3">h (*)</a></li>
<li><a href="#i-3">i (*)</a></li>
<li><a href="#j-2">j (*)</a></li>
</ul></li>
<li><a href="#exercise-8.1-arma-models-and-unit-roots">Exercise 8.1 (ARMA Models and Unit Roots)</a><ul>
<li><a href="#a-5">a</a></li>
<li><a href="#b-5">b</a></li>
<li><a href="#c-5">c</a></li>
<li><a href="#d-5">d</a></li>
<li><a href="#e-5">e</a></li>
<li><a href="#f-5">f</a></li>
<li><a href="#g-5">g</a></li>
<li><a href="#h-4">h (*)</a></li>
<li><a href="#i-4">i</a></li>
<li><a href="#j-3">j</a></li>
<li><a href="#k-1">k (*)</a></li>
<li><a href="#l-1">l (*)</a></li>
<li><a href="#m-1">m (*)</a></li>
</ul></li>
<li><a href="#exercise-9.2-cointegration">Exercise 9.2 (Cointegration)</a><ul>
<li><a href="#a-6">a</a></li>
<li><a href="#b-6">b</a></li>
<li><a href="#c-6">c</a></li>
<li><a href="#d-6">d</a></li>
<li><a href="#e-6">e</a></li>
<li><a href="#f-6">f</a></li>
<li><a href="#g-6">g</a></li>
<li><a href="#h-5">h</a></li>
<li><a href="#i-5">i</a></li>
<li><a href="#j-4">j</a></li>
<li><a href="#k-2">k (*)</a></li>
<li><a href="#l-2">l (*)</a></li>
<li><a href="#m-2">m (*)</a></li>
<li><a href="#n-1">n (*)</a></li>
</ul></li>
<li><a href="#exercise-9.3-cointegration---empirical">Exercise 9.3 (Cointegration - Empirical)</a><ul>
<li><a href="#a-7">a</a></li>
<li><a href="#b-7">b</a></li>
<li><a href="#c-7">c</a></li>
<li><a href="#d-7">d</a></li>
<li><a href="#e-7">e</a></li>
<li><a href="#f-7">f</a></li>
</ul></li>
</ul>
</div>

<p>Textbook: <a href="http://93.174.95.27/book/index.php?md5=744048ECF4C4A865F45A5877AA7C2BD5">A Guide to Modern Econometrics</a><br />
(no access): <a href="http://bcs.wiley.com/he-bcs/Books?action=index&amp;bcsId=10946&amp;itemId=1119148650">Instructor Companion Site</a></p>
<ul>
<li><input type="checkbox" disabled="" checked="" />
<a href="#exercise-2.1-regression">Exercise 2.1</a></li>
<li><input type="checkbox" disabled="" checked="" />
<a href="#exercise-2.4-regression---true-or-false">Exercise 2.4</a></li>
<li><input type="checkbox" disabled="" />
<a href="#exercise-3.2-regression---empirical">Exercise 3.2</a></li>
<li><input type="checkbox" disabled="" />
<a href="#exercise-3.4-regression---empirical">Exercise 3.4</a></li>
<li><input type="checkbox" disabled="" checked="" />
<a href="#exercise-5.1-instrumental-variables">Exercise 5.1</a></li>
<li><input type="checkbox" disabled="" />
<a href="#exercise-5.2-return-s-to-schooling---empirical">Exercise 5.2</a></li>
<li><input type="checkbox" disabled="" checked="" />
<a href="#exercise-7.1-binary-choice-models">Exercise 7.1</a></li>
<li><input type="checkbox" disabled="" checked="" />
<a href="#exercise-8.1-arma-models-and-unit-roots">Exercise 8.1</a></li>
<li><input type="checkbox" disabled="" checked="" />
<a href="#exercise-9.2-cointegration">Exercise 9.2</a></li>
<li><input type="checkbox" disabled="" />
<a href="#exercise-9.3-cointegration---empirical">Exercise 9.3</a></li>
</ul>
<div id="exercise-2.1-regression" class="section level2">
<h2>Exercise 2.1 (Regression)</h2>
<blockquote>
<p>Consider the following linear regression model:<br />
<span class="math display">\[\begin{aligned}y_i &amp;= β_1 + β_2x_{i2} + β_3x_{i3} + ε_i \\ &amp;= x_i&#39;β + ε_i\end{aligned}\]</span></p>
</blockquote>
<div id="a" class="section level3">
<h3>a</h3>
<blockquote>
<p>Explain how the ordinary least squares estimator for <span class="math inline">\(β\)</span> is determined, and derive an expression for <span class="math inline">\(b\)</span>.</p>
</blockquote>
<p>slide 2 P9</p>
<p>Solve minimization problem:
<span class="math display">\[\begin{aligned}\min_{β} &amp;&amp; S(β) = (y - Xβ)&#39;(y - Xβ)\end{aligned}\]</span>
<span class="math display">\[b = (X&#39;X)^{-1}X&#39;y\]</span></p>
</div>
<div id="b" class="section level3">
<h3>b</h3>
<blockquote>
<p>Which assumptions are needed to make <span class="math inline">\(b\)</span> an unbiased estimator for <span class="math inline">\(β\)</span>?</p>
</blockquote>
<p>slide 2 P24</p>
<p><span class="math inline">\(E[ε_i] = 0\)</span> and <span class="math inline">\(\{ε_1, \dots , ε_n\}\)</span> and <span class="math inline">\(\{x_1, \dots , x_N\}\)</span> are independent (A1, A2)</p>
</div>
<div id="c" class="section level3">
<h3>c</h3>
<blockquote>
<p>Explain how a confidence interval for <span class="math inline">\(β_2\)</span> can be constructed.<br />
Which additional assumptions are needed?</p>
</blockquote>
<p>textbook P25</p>
<p>95% confidence interval: <span class="math inline">\([b_2 - 1.96\cdot se(b_2), b_2 + 1.96\cdot se(b_2)]\)</span><br />
Assumptions: <span class="math inline">\(Var(ε_i) = σ^2\)</span> and <span class="math inline">\(Cov(ε_i, ε_j) = 0\)</span> for all <span class="math inline">\(i\neq j\)</span> (for estimating standard error)</p>
</div>
<div id="d" class="section level3">
<h3>d</h3>
<blockquote>
<p>Explain how one can test the hypothesis that <span class="math inline">\(β_3 = 1\)</span></p>
</blockquote>
<p>slide 3 P12</p>
<p>H0: <span class="math inline">\(β_3 - 1 = 0\)</span><br />
H1: <span class="math inline">\(β_3 - 1 \neq 0\)</span><br />
Let <span class="math inline">\(t = \frac{b_3 - 1}{se(b_3)}\)</span> follows a <span class="math inline">\(t_{N-3}\)</span><br />
If <span class="math inline">\(|t| &gt; t_{N-3, α/2}\)</span>, then H0 is rejected.</p>
</div>
<div id="e" class="section level3">
<h3>e</h3>
<blockquote>
<p>Explain how one can test the hypothesis that <span class="math inline">\(β_2 + β_3 = 0\)</span></p>
</blockquote>
<p>slide 3 P16</p>
<p>H0: <span class="math inline">\(β_2 + β_3 = 0\)</span><br />
H1: <span class="math inline">\(β_2 + β_3\neq 0\)</span><br />
Let <span class="math inline">\(t = \frac{b_2 + b_3}{se(b_2 + b_3)}\)</span><br />
If <span class="math inline">\(|t| &gt; t_{N-3, α/2}\)</span>, then H0 is rejected.</p>
</div>
<div id="f" class="section level3">
<h3>f</h3>
<blockquote>
<p>Explain how one can test the hypothesis that <span class="math inline">\(β_2 = β_3 = 0\)</span></p>
</blockquote>
<p>slide 3 P18</p>
<p>H0: <span class="math inline">\(\begin{cases} β_2 = 0 \\ β_3 = 0\end{cases}\)</span><br />
H1: <span class="math inline">\(\begin{aligned} &amp; β_2 \neq 0 \\\text{or } &amp; β_3 = 0\end{aligned}\)</span><br />
Let <span class="math inline">\(F = \frac{N-3}{2}\cdot\frac{R^2}{1-R^2}\)</span><br />
If <span class="math inline">\(F &gt; F_{N-3}^2\)</span>, then H0 is rejected.</p>
</div>
<div id="g" class="section level3">
<h3>g</h3>
<blockquote>
<p>Which assumptions are needed to make <span class="math inline">\(b\)</span> a consistent estimator for <span class="math inline">\(b\)</span>?</p>
</blockquote>
<p>textbook P49</p>
<p><span class="math inline">\(\frac{1}{N} \sum^N_{i=1} x_ix_i&#39; \to^p \exists Σ_{xx}\)</span> and <span class="math inline">\(E[ε_i x_i] = 0\)</span> (A6, A7)</p>
</div>
<div id="h" class="section level3">
<h3>h</h3>
<blockquote>
<p>Suppose that <span class="math inline">\(x_{i2} = 2 + 3x_{i3}\)</span><br />
What will happen if you try to estimate the above model?</p>
</blockquote>
<p>slide 3 P22, textbook P59</p>
<p>No-multicollinearity assumption is violated, so the regression results become unreliable.</p>
</div>
<div id="i" class="section level3">
<h3>i</h3>
<blockquote>
<p>Suppose that the model is estimated with <span class="math inline">\(x^*_{i2} = 2x_{i2} − 2\)</span> included rather than <span class="math inline">\(x_{i2}\)</span><br />
How are the coefficients in this model related to those in the original model?<br />
And the <span class="math inline">\(R^2\)</span>’s?</p>
</blockquote>
<p><a href="https://www2.stat.duke.edu/~hc95/Teaching/STA103/lec14_notes.pdf">Lecture 14 Simple Linear Regression</a></p>
<p><span class="math display">\[\begin{aligned}y_i &amp;= β_1 + β_2x_{i2} + β_3x_{i3} + ε_i \\
&amp;= β_1 + β_2\cdot\frac{x^*_{i2} - 2}{2} + β_3x_{i3} + ε_i \\
&amp;= β_1 + β_2\cdot\frac{-2}{2} + β_2\cdot\frac{x^*_{i2}}{2} + β_3x_{i3} + ε_i\\
&amp;= β_1&#39; + β_2&#39;x^*_{i2} + β_3&#39;x_{i3} + ε_i \end{aligned}\]</span>
Therefore,
<span class="math display">\[\begin{aligned} b_1&#39; &amp;= b_1 - b_2 \\
b_2&#39; &amp;= \frac{b_2}{2}\end{aligned}\]</span>
and <span class="math inline">\(b_3\)</span> and <span class="math inline">\(R^2\)</span> remain unchanged.</p>
</div>
<div id="j" class="section level3">
<h3>j</h3>
<blockquote>
<p>Suppose that <span class="math inline">\(x_{i2} = x_{i3} + u_i\)</span>, where <span class="math inline">\(u_i\)</span> and <span class="math inline">\(x_{i3}\)</span> are uncorrelated.<br />
Suppose that the model is estimated with <span class="math inline">\(u_i\)</span> included rather than <span class="math inline">\(x_{i2}\)</span><br />
How are the coefficients in this model related to those in the original model?<br />
And the <span class="math inline">\(R^2\)</span>’s?</p>
</blockquote>
<p><span class="math display">\[\begin{aligned} y_i &amp;= β_1 + β_2x_{i2} + β_3x_{i3} + ε_i \\
&amp;= β_1 + β_2\cdot(x_{i3} + u_i) + β_3x_{i3} + ε_i \\
&amp;= β_1 + β_2u_i + (β_2 + β_3)\cdot x_{i3} + ε_i \\
&amp;= β_1&#39; + β_2&#39; u_i + β_3&#39;x_{i3} + ε_i \\\end{aligned}\]</span>
Therefore, <span class="math inline">\(β_3&#39; = β_2 + β_3\)</span>, other coefficients and <span class="math inline">\(R^2\)</span> remain unchanged.</p>
</div>
</div>
<div id="exercise-2.4-regression---true-or-false" class="section level2">
<h2>Exercise 2.4 (Regression - True or False?)</h2>
<div id="a-1" class="section level3">
<h3>a</h3>
<blockquote>
<p>Under the Gauss–Markov conditions, OLS can be shown to be BLUE.<br />
The phrase ‘linear’ in this acronym refers to the fact that we are <strong>estimating a linear model</strong>.</p>
</blockquote>
<p><a href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Markov_theorem?oldformat=true#Linearity">Gauss–Markov theorem - Wikipedia</a></p>
<p>False.<br />
‘Linear’ means the estimator is a linear function of the dependent variable.</p>
</div>
<div id="b-1" class="section level3">
<h3>b</h3>
<blockquote>
<p>In order to apply a t-test, the <strong>(all) Gauss–Markov conditions</strong> are strictly required.</p>
</blockquote>
<p>textbook P141<br />
<a href="http://thestatsgeek.com/2013/09/28/the-t-test-and-robustness-to-non-normality/">The t-test and robustness to non-normality – The Stats Geek</a><br />
<a href="https://en.wikipedia.org/wiki/Student%27s_t-test?oldformat=true#Alternatives_to_the_t-test_for_location_problems">Student’s t-test - Wikipedia</a></p>
<p>False.<br />
The only assumption needed is <span class="math inline">\(ε_i\)</span> and <span class="math inline">\(x_i\)</span> are independent for all <span class="math inline">\(i\)</span> (A8).</p>
</div>
<div id="c-1" class="section level3">
<h3>c</h3>
<blockquote>
<p>A regression of the OLS residual upon the regressors included in the model by construction yields an <span class="math inline">\(R_2\)</span> of zero.</p>
</blockquote>
<p>slide 3 P19</p>
<p>True.</p>
</div>
<div id="d-1" class="section level3">
<h3>d</h3>
<blockquote>
<p>The hypothesis that the <strong>OLS estimator</strong> is equal to zero can be tested by means of a t-test.</p>
</blockquote>
<p>False.<br />
What is tested is the true coefficients, not the estimators.</p>
</div>
<div id="e-1" class="section level3">
<h3>e</h3>
<blockquote>
<p>From asymptotic theory, we learn that, under appropriate conditions, the <strong>error terms</strong> in a regression model will be approximately normally distributed if the sample size is sufficiently large.</p>
</blockquote>
<p>slide 4 P15</p>
<p>False.<br />
Asymptotic theory says the estimators will be approximately normal with a large sample size.<br />
The normality of error terms is an assumption.</p>
</div>
<div id="f-1" class="section level3">
<h3>f</h3>
<blockquote>
<p>If the absolute t-value of a coefficient is smaller than 1.96, we <strong>accept</strong> the null hypothesis that the coefficient is zero, with 95% confidence.</p>
</blockquote>
<p>False.<br />
We do not accept H0, we just can not reject it. A small t-value does not necessarily mean that H0 is correct.</p>
</div>
<div id="g-1" class="section level3">
<h3>g</h3>
<blockquote>
<p>Because OLS provides the <strong>best linear approximation</strong> of a variable <span class="math inline">\(y\)</span> from a set of regressors, OLS also gives <strong>best linear unbiased estimators</strong> for the coefficients of these regressors.</p>
</blockquote>
<p>False.<br />
OLS provides the best linear approximation of <span class="math inline">\(y\)</span> by the construction of OLS method,<br />
but whether an estimator is BLUE depends on whether the Gauss-Markov assumptions are satisfied.</p>
</div>
<div id="h-1" class="section level3">
<h3>h</h3>
<blockquote>
<p>If a variable in a model is significant at the X10% level, it is also significant at the 5% level.</p>
</blockquote>
<p>False.<br />
Significance at 10% level is weaker than at 5% level.</p>
</div>
<div id="i-1" class="section level3">
<h3>i</h3>
<blockquote>
<p>For hypothesis testing, the p-value is <strong>more informative</strong> than a confidence interval.</p>
</blockquote>
<p>textbook P24</p>
<p>False.<br />
Confidence interval indicate magnitude and precision of a coefficient, whereas the p-value provides only the latter.</p>
</div>
<div id="j-1" class="section level3">
<h3>j</h3>
<blockquote>
<p>It is <strong>advisable to remove outliers</strong> from a data set as this leads to lower standard errors for the OLS estimator.</p>
</blockquote>
<p>textbook P48, slide 3 P25</p>
<p>False.<br />
If the outliers are correct data points, removing them may result in a less precise estimation.</p>
</div>
<div id="k" class="section level3">
<h3>k</h3>
<blockquote>
<p>The p-value of a test corresponds to the probability that the <strong>null hypothesis is true</strong>.</p>
</blockquote>
<p>textbook P31</p>
<p>False.<br />
p-value is the probability that the reported test statistic occurs (H0 cannot be rejected).<br />
H0 is not rejected does not equalize to it being true, and vice versa.</p>
</div>
<div id="l" class="section level3">
<h3>l</h3>
<blockquote>
<p><strong>To prevent multicollinearity</strong>, two explanatory variables with a correlation of 0.9 should not be included in the same regression model.</p>
</blockquote>
<p>textbook P45, slide 3 P22</p>
<p>False.<br />
With such a high correlation, it becomes hard to identify individual impact of each variable.<br />
However, omitting one of them may result in less precise estimation for other estimators.<br />
Preferred solutions include increasing sample size and variation of the variables.</p>
</div>
<div id="m" class="section level3">
<h3>m</h3>
<blockquote>
<p>Consider a regression model with two explanatory variables, <span class="math inline">\(x_2\)</span> and <span class="math inline">\(x_3\)</span>, and a constant.<br />
Other things equal, the variance of the OLS estimator <span class="math inline">\(b_2\)</span> for <span class="math inline">\(β_2\)</span> is larger if <span class="math inline">\(x_2\)</span> and <span class="math inline">\(x_3\)</span> are moderately negatively correlated than if they are uncorrelated.</p>
</blockquote>
<p>textbook P45</p>
<p>True.</p>
</div>
<div id="n" class="section level3">
<h3>n</h3>
<blockquote>
<p>Suppose we are interested in the impact of beauty upon a person’s wage (the ‘beauty premium’, see Hamermesh and Biddle, 1994).<br />
If a beauty premium exists, we should find a <strong>positive and statistically significant</strong> estimate for its coefficient in a wage equation.</p>
</blockquote>
<p>False.<br />
1. We do not know if the premium is positive or negative. As long as the coefficient is not zero, beauty premium exists.<br />
2. Statistically significance is not the only element to consider when evaluating the estimator.</p>
</div>
</div>
<div id="exercise-3.2-regression---empirical" class="section level2">
<h2>Exercise 3.2 (Regression - Empirical)</h2>
<blockquote>
<p>For this exercise we use data on sales, size and other characteristics of 400 Dutch men’s fashion stores.<br />
The goal is to explain sales per square metre (<span class="math inline">\(sales\)</span>) from the characteristics of the shop (number of owners, full-time and part-time workers, number of hours worked, shop size, etc.).</p>
</blockquote>
<div id="a-2" class="section level3">
<h3>a</h3>
<blockquote>
<p>Estimate a linear model (model A) that explains sales from total number of hours worked (<span class="math inline">\(hoursw\)</span>), shop size in square metres (<span class="math inline">\(ssize\)</span>) and a constant.<br />
Interpret the results.</p>
</blockquote>
</div>
<div id="b-2" class="section level3">
<h3>b</h3>
<blockquote>
<p>Perform Ramsey’s RESET test with <span class="math inline">\(Q = 2\)</span>.</p>
</blockquote>
</div>
<div id="c-2" class="section level3">
<h3>c</h3>
<blockquote>
<p>Test whether the number of owners (nown) affects shop sales, conditional upon <span class="math inline">\(hoursw\)</span> and <span class="math inline">\(ssize\)</span>.</p>
</blockquote>
</div>
<div id="d-2" class="section level3">
<h3>d</h3>
<blockquote>
<p>Also test whether the inclusion of the number of part-time workers (<span class="math inline">\(npart\)</span>) improves the model.</p>
</blockquote>
</div>
<div id="e-2" class="section level3">
<h3>e</h3>
<blockquote>
<p>Estimate a linear model (model B) that explains sales from the number of owners, full-time workers (<span class="math inline">\(nfull\)</span>), part-time workers and shop size.<br />
Interpret the results.</p>
</blockquote>
</div>
<div id="f-2" class="section level3">
<h3>f</h3>
<blockquote>
<p>Compare model A and model B on the basis of <span class="math inline">\(\bar{R}^2\)</span>, AIC and BIC.</p>
</blockquote>
</div>
<div id="g-2" class="section level3">
<h3>g</h3>
<blockquote>
<p>Perform a non-nested F-test of model A against model B.<br />
Perform a non-nested F-test of model B against model A.<br />
What do you conclude?</p>
</blockquote>
</div>
<div id="h-2" class="section level3">
<h3>h</h3>
<blockquote>
<p>Repeat the above test using the J-test.<br />
Does your conclusion change?</p>
</blockquote>
</div>
<div id="i-2" class="section level3">
<h3>i</h3>
<blockquote>
<p>Include the numbers of full-time and part-time workers in model A to obtain model C.<br />
Estimate this model.<br />
Interpret the results and perform a RESET test.<br />
Are you satisfied with this specification?</p>
</blockquote>
</div>
</div>
<div id="exercise-3.4-regression---empirical" class="section level2">
<h2>Exercise 3.4 (Regression - Empirical)</h2>
</div>
<div id="exercise-5.1-instrumental-variables" class="section level2">
<h2>Exercise 5.1 (Instrumental Variables)</h2>
<blockquote>
<p>Consider the following model
<span class="math display">\[\begin{aligned}y_i = β_1 + β_2x_{i2} + β_3x_{i3} + ε_i &amp;&amp; i = 1,\dots, N\end{aligned}\]</span>
where <span class="math inline">\((y_i, x_{i2}, x_{i3})\)</span> are observed and have finite moments, and <span class="math inline">\(ε_i\)</span> is an unobserved error term.<br />
Suppose this model is estimated by ordinary least squares.<br />
Denote the OLS estimator by <span class="math inline">\(b\)</span>.</p>
</blockquote>
<div id="a-3" class="section level3">
<h3>a</h3>
<blockquote>
<p>What are the essential conditions required for unbiasedness of <span class="math inline">\(b\)</span>?<br />
What are the essential conditions required for consistency of <span class="math inline">\(b\)</span>?<br />
Explain the difference between unbiasedness and consistency..</p>
</blockquote>
<p>slide 2 P24, textbook P35, textbook P34</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(E[ε_i] = 0\)</span> and <span class="math inline">\(\{ε_1, \dots , ε_n\}\)</span> and <span class="math inline">\(\{x_1, \dots , x_N\}\)</span> are independent (A1, A2)</li>
<li><span class="math inline">\(\frac{1}{N} \sum^N_{i=1} x_ix_i&#39; \to^p \exists Σ_{xx}\)</span> and <span class="math inline">\(E[ε_i x_i] = 0\)</span> (A6, A7)</li>
<li>Unbiasedness is stronger than consistency.<br />
An unbiased estimator is expected to be true value, whereas a consistent estimator is expected to converge in probability to the true value.</li>
</ol>
</div>
<div id="b-3" class="section level3">
<h3>b</h3>
<blockquote>
<p>Show how the conditions for consistency can be written as moment conditions (if you have not done so already).<br />
Explain how a method of moments estimator can be derived from these moment conditions.<br />
Is the resulting estimator any different from the OLS one?</p>
</blockquote>
<p>textbook P177, slide 9-1 P6</p>
<p><span class="math display">\[\begin{aligned}E[ε_i x_i] &amp;= 0 \\
E\big[(y_i - x_i&#39;β)\cdot x_i\big] &amp;= 0 \\
\sum_N \big[(y_i - x_i&#39;b)\cdot x_i\big] &amp;= 0 \\
b &amp;= \frac{\sum_N x_iy_i}{\sum_N x_ix_i&#39;}\end{aligned}\]</span>
<!-- The method of moments estimator is obtained by taking the sample expectations, and solving for $b$. -->
The resulting estimator is exactly same as the OLS estimator.</p>
<blockquote>
<p>Now suppose that <span class="math inline">\(Cov(ε_i, x_{i3})\neq 0\)</span></p>
</blockquote>
</div>
<div id="c-3" class="section level3">
<h3>c</h3>
<blockquote>
<p>Give two examples of cases where one can expect a nonzero correlation between a regressor, <span class="math inline">\(x_{i3}\)</span>, and the error <span class="math inline">\(ε_i\)</span>.</p>
</blockquote>
<p>textbook P144 146 148</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(x_{i3}\)</span> is subject to measurement error</li>
<li><span class="math inline">\(x_{i3}\)</span> and <span class="math inline">\(y_i\)</span> are correlated with the same unobserved factor (omitted variable bias)</li>
<li><span class="math inline">\(x_{i3}\)</span> and <span class="math inline">\(y_i\)</span> have reverse causality</li>
</ol>
</div>
<div id="d-3" class="section level3">
<h3>d</h3>
<blockquote>
<p>In this case, is it possible still to make appropriate inferences based on the OLS estimator while adjusting the standard errors appropriately?</p>
</blockquote>
<p>textbook P143</p>
<p>Nothing can be done if assumption <span class="math inline">\(E[ε_i x_i] = 0\)</span> is violated.</p>
</div>
<div id="e-3" class="section level3">
<h3>e</h3>
<blockquote>
<p>Explain how an instrumental variable, <span class="math inline">\(z_i\)</span>, say, leads to a new moment condition and, consequently, an alternative estimator for <span class="math inline">\(β\)</span>.</p>
</blockquote>
<p>slide 9-1 P6</p>
<p>Moment condisions:<br />
<span class="math display">\[\begin{cases} E[y_i - x_{i}&#39;β] &amp;= 0 \\
E\big[(y_i - x_{i}&#39;β)\cdot x_{i3}\big] &amp;= 0 \\
E\big[(y_i - x_{i}&#39;β)\cdot z_i\big] &amp;= 0 \end{cases}\]</span>
Estimation:<br />
<span class="math display">\[\begin{aligned}\sum_N \big[(y_i - x_{i1}&#39;\hat{β}_{IV,1} - x_{i2}&#39;\hat{β}_{IV,2}- x_{i3}&#39;\hat{β}_{IV,3})\cdot z_i\big] &amp;= 0 \\
\hat{β}_{IV} &amp;= \frac{\sum_N z_iy_i}{\sum_N z_ix_i&#39;}\end{aligned}\]</span></p>
</div>
<div id="f-3" class="section level3">
<h3>f</h3>
<blockquote>
<p>Why does this alternative estimator lead to a smaller <span class="math inline">\(R^2\)</span> than the OLS one?<br />
What does this say of the <span class="math inline">\(R^2\)</span> as a measure for the adequacy of the model?</p>
</blockquote>
<p>textbook P22</p>
<ol style="list-style-type: decimal">
<li>OLS estimator, by construction, uniquely maximizes <span class="math inline">\(R^2\)</span>.<br />
Therefore, using an instrument variable will certainly decrease <span class="math inline">\(R^2\)</span>.<br />
</li>
<li><span class="math inline">\(R^2\)</span> is only applicable with OLS models.</li>
</ol>
</div>
<div id="g-3" class="section level3">
<h3>g</h3>
<blockquote>
<p>Why can we not choose <span class="math inline">\(z_i = x_{i2}\)</span> as an instrument for <span class="math inline">\(x_{i3}\)</span>, even if <span class="math inline">\(E[x_{i2}ε_i] = 0\)</span>?<br />
Would it be possible to use <span class="math inline">\(x_{i2}^2\)</span> as an instrument for <span class="math inline">\(x_{i3}\)</span>?</p>
</blockquote>
<ol style="list-style-type: decimal">
<li>Because using <span class="math inline">\(z_i\)</span> and <span class="math inline">\(x_{i2}\)</span> at the same time will cause perfect multicollinearity.<br />
</li>
<li>If <span class="math inline">\(Cov(x_{i2}^2, x_{i3})\neq 0\)</span>, and the functional form is correct, it is possible to use <span class="math inline">\(x_{i2}^2\)</span>.</li>
</ol>
</div>
</div>
<div id="exercise-5.2-returns-to-schooling---empirical" class="section level2">
<h2>Exercise 5.2 (Returns to Schooling - Empirical)</h2>
</div>
<div id="exercise-7.1-binary-choice-models" class="section level2">
<h2>Exercise 7.1 (Binary Choice Models)</h2>
<blockquote>
<p>For a sample of 600 married females, we are interested in explaining participation in market employment from exogenous characteristics in <span class="math inline">\(x_i\)</span> (age, family composition, education).<br />
Let <span class="math inline">\(y_i = 1\)</span> if person i has a paid job and 0 otherwise.<br />
Suppose we estimate a linear regression model <span class="math display">\[y_i = x_i&#39;β + ε_i\]</span> by ordinary least squares.</p>
</blockquote>
<div id="a-4" class="section level3">
<h3>a</h3>
<blockquote>
<p>Give two reasons why this is not really an appropriate model.</p>
</blockquote>
<p>slide 11 P5</p>
<ol style="list-style-type: decimal">
<li>Values of predicted <span class="math inline">\(y_i\)</span> in OLS model may not be in the range <span class="math inline">\([0,1]\)</span></li>
<li>Linear model implies that the value of <span class="math inline">\(x_i&#39;β\)</span> is probability</li>
</ol>
<blockquote>
<p>As an alternative, we could model the participation decision by a probit model.</p>
</blockquote>
</div>
<div id="b-4" class="section level3">
<h3>b</h3>
<blockquote>
<p>Explain the probit model.</p>
</blockquote>
<p>slide 11 P7-8 15</p>
<p>We assume <span class="math inline">\(Pr(y_i = 1 \ | x_i)\)</span> follows standard normal distribution <span class="math inline">\(Φ(x&#39;β)\)</span>,<br />
and use estimation methods like maximum likelihood to estimate <span class="math inline">\(β\)</span>.</p>
</div>
<div id="c-4" class="section level3">
<h3>c</h3>
<blockquote>
<p>Give an expression for the log-likelihood function of the probit model.</p>
</blockquote>
<p>slide 11 P15</p>
<p><span class="math inline">\(\log L(β) = \sum_N y_i \cdot\log\big(Φ(x&#39;β)\big) + \sum_N (1 - y_i) \cdot\log\big(1 - Φ(x&#39;β)\big)\)</span></p>
</div>
<div id="d-4" class="section level3">
<h3>d</h3>
<blockquote>
<p>How would you interpret a positive <span class="math inline">\(β\)</span> coefficient for education in the probit model?</p>
</blockquote>
<p><a href="https://stats.stackexchange.com/a/42960/147391">How do I interpret a probit model in Stata? - Cross Validated</a><br />
<a href="https://www.theanalysisfactor.com/the-difference-between-logistic-and-probit-regression/">The Difference Between Logistic and Probit Regression - The Analysis Factor</a></p>
<p>Since the probability of <span class="math inline">\(y_i = 1\)</span> follows <span class="math inline">\(Φ(x&#39;β)\)</span>,<br />
a positive <span class="math inline">\(β\)</span> means a unit increase in <span class="math inline">\(x_i\)</span> is associated with an increase in <span class="math inline">\(Pr(y_i = 1)\)</span>, everything else hold equal.</p>
</div>
<div id="e-4" class="section level3">
<h3>e</h3>
<blockquote>
<p>Suppose you have a person with <span class="math inline">\(x_i&#39;β = 2\)</span><br />
What is your prediction for her labour market status <span class="math inline">\(y_i\)</span>? Why?</p>
</blockquote>
<p><a href="https://keisan.casio.com/exec/system/1180573191">Standard normal distribution Calculator</a></p>
<p><span class="math display">\[\begin{aligned} Pr(y_i = 1) &amp;= Φ(2) \\ &amp;= 0.9772 \end{aligned}\]</span></p>
<p>My prediction is that her <span class="math inline">\(y_i = 1\)</span>.</p>
</div>
<div id="f-4" class="section level3">
<h3>f</h3>
<blockquote>
<p>To what extent is a logit model different from a probit model?</p>
</blockquote>
<p>slide 11 P10</p>
<ol style="list-style-type: decimal">
<li>Shape of distribution is slightly different</li>
<li>Scaling of the distribution is different</li>
<li>Probit model is easier to extend to multivariate cases</li>
</ol>
<blockquote>
<p>Now assume that we have a sample of women who are not working (<span class="math inline">\(y_i = 0\)</span>), part-time working (<span class="math inline">\(y_i = 1\)</span>) or full-time working (<span class="math inline">\(y_i = 2\)</span>).</p>
</blockquote>
</div>
<div id="g-4" class="section level3">
<h3>g (*)</h3>
<blockquote>
<p>Is it appropriate, in this case, to specify a linear model as <span class="math inline">\(y_i = x_i&#39;β + ε_i\)</span>?</p>
</blockquote>
<p>No, because there is still no guarantee that the value of <span class="math inline">\(y_i\)</span> falls into range <span class="math inline">\([0,2]\)</span>.</p>
</div>
<div id="h-3" class="section level3">
<h3>h (*)</h3>
<blockquote>
<p>What alternative model could be used instead that exploits the information contained in part-time versus full-time working?</p>
</blockquote>
<p>textbook P230</p>
<p>Multi-response models (ordered response models).</p>
</div>
<div id="i-3" class="section level3">
<h3>i (*)</h3>
<blockquote>
<p>How would you interpret a positive <span class="math inline">\(β\)</span> coefficient for education in this latter model?</p>
</blockquote>
</div>
<div id="j-2" class="section level3">
<h3>j (*)</h3>
<blockquote>
<p>Would it be appropriate to pool the two outcomes <span class="math inline">\(y_i = 1\)</span> and <span class="math inline">\(y_i = 2\)</span> and estimate a binary choice model?<br />
Why or why not?</p>
</blockquote>
<p>Depends on what the research is focused on.<br />
If the purpose is to explain whether or not women are employed, the form of employment should not matter, so pooling provides more data.<br />
On the other hand, if the form of employment is of interest, we should not pool.</p>
</div>
</div>
<div id="exercise-8.1-arma-models-and-unit-roots" class="section level2">
<h2>Exercise 8.1 (ARMA Models and Unit Roots)</h2>
<blockquote>
<p>A researcher uses a sample of 200 quarterly observations on <span class="math inline">\(Y_t\)</span>, the number (in 1000s) of unemployed persons, to model the time series behaviour of the series and to generate predictions.<br />
First, he computes the sample autocorrelation function, with the following results:</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(k\)</span></th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\hat{ρ}_k\)</span></td>
<td>0.83</td>
<td>0.71</td>
<td>0.60</td>
<td>0.45</td>
<td>0.44</td>
<td>0.35</td>
<td>0.29</td>
<td>0.20</td>
<td>0.11</td>
<td>-0.01</td>
</tr>
</tbody>
</table>
</blockquote>
<div id="a-5" class="section level3">
<h3>a</h3>
<blockquote>
<p>What do we mean by the sample autocorrelation function?<br />
Does the above pattern indicate that an autoregressive or moving average representation is more appropriate?<br />
Why?</p>
</blockquote>
<p>textbook P317</p>
<p>Sample ACF <span class="math inline">\(\hat{ρ}_k\)</span> is the estimated correlation coefficient between <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(Y_{t-k}\)</span>
The pattern indicates an autoregressive process, because the length of memory is long.</p>
<blockquote>
<p>Next, the sample partial autocorrelation function is determined. It is given by</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(k\)</span></th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\hat{θ}_{kk}\)</span></td>
<td>0.83</td>
<td>0.16</td>
<td>-0.09</td>
<td>0.05</td>
<td>0.04</td>
<td>-0.05</td>
<td>0.01</td>
<td>0.10</td>
<td>-0.03</td>
<td>-0.01</td>
</tr>
</tbody>
</table>
</blockquote>
</div>
<div id="b-5" class="section level3">
<h3>b</h3>
<blockquote>
<p>What do we mean by the sample partial autocorrelation function?<br />
Why is the first partial autocorrelation equal to the first autocorrelation coefficient (0.83)?</p>
</blockquote>
<p>textbook P318<br />
<a href="https://newonlinecourses.science.psu.edu/stat510/node/62/">Partial Autocorrelation Function (PACF) | STAT 510</a></p>
<p>Sample PACF <span class="math inline">\(\hat{θ}_{kk}\)</span> is the estimated correlation coefficient between <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(Y_{t-k}\)</span> in a model with k lags.</p>
<p><span class="math inline">\(\hat{ρ}_1\)</span> is the correlation between <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(Y_{t-1}\)</span>, where as <span class="math inline">\(\hat{θ}_{kk}\)</span> is the correlation between <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(Y_{t-1}\)</span> in a hypothetical progress as the unique lag,<br />
so they are by construction the same.</p>
</div>
<div id="c-5" class="section level3">
<h3>c</h3>
<blockquote>
<p>Does the above pattern indicate that an autoregressive or moving average representation is more appropriate?<br />
Why?</p>
</blockquote>
<p>The values of sample PACF are close to zero, indicating an autoregressive process.</p>
<blockquote>
<p>The researcher decides to estimate, as a first attempt, a first-order autoregressive model given by
<span class="math display">\[Y_t = δ + θY_{t−1} + ε_t\]</span>
The estimated value for <span class="math inline">\(θ_1\)</span> is 0.83 with a standard error of 0.07.</p>
</blockquote>
</div>
<div id="d-5" class="section level3">
<h3>d</h3>
<blockquote>
<p>Which estimation method is appropriate for estimating the AR(1) model?<br />
Explain why it is consistent.</p>
</blockquote>
<p>textbook P314</p>
<p>OLS estimation.<br />
Since <span class="math inline">\(E[Y_{t-j}ε_t] = 0\)</span> for all j, (A7) of Gauss-Markov Assumptions is satisfied, so OLS estimator should be consistent.</p>
</div>
<div id="e-5" class="section level3">
<h3>e</h3>
<blockquote>
<p>The researcher wants to test for a unit root.<br />
What is meant by ‘a unit root’?<br />
What are the implications of the presence of a unit root?<br />
Why are we interested in it? (Give statistical or economic reasons.)</p>
</blockquote>
<p>slide 12 P16, textbook P298-299</p>
<p>Unit root means the characteristic root <span class="math inline">\(|z| = 1\)</span>.<br />
With the presence of a unit root, the process is non-stationary.<br />
Detecting a unit root is important because it is the boundary case between stationary (<span class="math inline">\(|z| &gt; 1\)</span>) and non-stationary.</p>
</div>
<div id="f-5" class="section level3">
<h3>f</h3>
<blockquote>
<p>Formulate the hypothesis of a unit root and perform a unit root test based on the above regression.</p>
</blockquote>
<p>slide 12 P20 22</p>
<p>H0: <span class="math inline">\(θ - 1 = 0\)</span><br />
H1: <span class="math inline">\(θ - 1 &lt; 0\)</span><br />
<span class="math display">\[\begin{aligned}DF &amp;= \frac{\hat{θ} - 1}{se(\hat{θ})} \\
&amp;= \frac{0.83 - 1}{0.07} \\
&amp;= -2.4286\end{aligned}\]</span>
Cannot reject the H0 at 5% level, maybe at 10% level.</p>
</div>
<div id="g-5" class="section level3">
<h3>g</h3>
<blockquote>
<p>Perform a test for the null hypothesis that <span class="math inline">\(θ = 0.90\)</span></p>
</blockquote>
<p>H0: <span class="math inline">\(θ - 0.90 = 0\)</span><br />
H0: <span class="math inline">\(θ - 0.90 &lt; 0\)</span><br />
<span class="math display">\[\begin{aligned}DF &amp;= \frac{\hat{θ} - 1}{se(\hat{θ})} \\
&amp;= \frac{0.83 - 0.90}{0.07} \\
&amp;= -1\end{aligned}\]</span>
Cannot reject the H0.</p>
<blockquote>
<p>Next, the researcher extends the model to an AR(2), with the following results (standard errors in parentheses):
<span class="math display">\[\begin{aligned}Y_t &amp;= 50.0 + 0.74Y_{t−1} + 0.16 Y_{t-2}+ \hat{ε}_t \\ &amp;\phantom{\gg} (5.67) \phantom{0} (0.07) \phantom{Y_{t-1} 0} (0.07) \end{aligned}\]</span></p>
</blockquote>
</div>
<div id="h-4" class="section level3">
<h3>h (*)</h3>
<blockquote>
<p>Would you prefer the AR(2) model to the AR(1) model?<br />
How would you check whether an ARMA(2, 1) model may be more appropriate?</p>
</blockquote>
<p><span class="math display">\[\begin{aligned}z_{\hat{θ}_2} &amp;= \frac{0.16}{0.07} = 2.2857 ∼ \mathcal{N} \\
Pr(z &gt; 2.2857) &amp;= 0.0113\end{aligned}\]</span>
Therefore, I prefer AR(2) model to the AR(1) model.</p>
<p>Check ARMA(2, 1)?</p>
</div>
<div id="i-4" class="section level3">
<h3>i</h3>
<blockquote>
<p>What do the above results tell you about the validity of the unit root test of (f)?</p>
</blockquote>
<p><a href="https://stats.stackexchange.com/a/235916/147391">What is the difference between a stationary test and a unit root test? - Cross Validated</a></p>
<p>The power of the test is relatively weak, maybe because <span class="math inline">\(\hat{θ}\)</span> is close to 1.</p>
</div>
<div id="j-3" class="section level3">
<h3>j</h3>
<blockquote>
<p>How would you test for the presence of a unit root in the AR(2) model?</p>
</blockquote>
<p>textbook P304</p>
<p>ADF test: H0: <span class="math inline">\(θ_1 + θ_2 - 1 = 0\)</span><br />
H1: <span class="math inline">\(θ_1 + θ_2 - 1 &lt; 0\)</span><br />
<span class="math inline">\(DF = \frac{\hat{θ_1} + \hat{θ_2} - 1}{se(\hat{θ_1} + \hat{θ_2} - 1)}\)</span></p>
</div>
<div id="k-1" class="section level3">
<h3>k (*)</h3>
<blockquote>
<p>From the above estimates, compute an estimate for the average number of unemployed <span class="math inline">\(E\{Y_t\}\)</span></p>
</blockquote>
</div>
<div id="l-1" class="section level3">
<h3>l (*)</h3>
<blockquote>
<p>Suppose the last two quarterly unemployment levels for 2016:III and 2016:IV were 550 and 600, respectively.<br />
Compute forecasts for 2017:I and 2017:II.</p>
</blockquote>
</div>
<div id="m-1" class="section level3">
<h3>m (*)</h3>
<blockquote>
<p>Can you say anything sensible about the forecasted value for the quarter 2037:I?<br />
And its accuracy?</p>
</blockquote>
</div>
</div>
<div id="exercise-9.2-cointegration" class="section level2">
<h2>Exercise 9.2 (Cointegration)</h2>
<blockquote>
<p>Consider the following very simple relationship between aggregate savings <span class="math inline">\(S_t\)</span> and aggregate income <span class="math inline">\(Y_t\)</span>:
<span class="math display">\[\begin{aligned}S_t = α + βY_t + ε_t &amp;&amp; t=1,\dots, T \end{aligned}\]</span>
For some country this relationship is estimated by OLS over the years 1956–2005 (<span class="math inline">\(T = 50\)</span>).<br />
The results are given in Table 9.17.<br />
<img src="/post-img/notes-stat1-exercise--9-2.png" width="388" />
Assume, for the moment, that the series <span class="math inline">\(S_t\)</span> and <span class="math inline">\(Y_t\)</span> are stationary.<br />
Hint: if needed, consult Chapter 4 for the first set of questions.</p>
</blockquote>
<div id="a-6" class="section level3">
<h3>a</h3>
<blockquote>
<p>How would you interpret the coefficient estimate of 0.098 for the income variable?</p>
</blockquote>
<p>A unit change in income is correlated with 0.098 unit change in savings, everything else hold equal.</p>
</div>
<div id="b-6" class="section level3">
<h3>b</h3>
<blockquote>
<p>Explain why the results indicate that there may be a problem of positive autocorrelation.<br />
Can you give arguments why, in economic models, positive autocorrelation is more likely than negative autocorrelation?</p>
</blockquote>
<p>slide 7 P7<br />
<a href="https://www.displayr.com/autocorrelation/">What is Autocorrelation? | Autocorrelation examples</a></p>
<p>The Durbin-Watson statistics <span class="math inline">\(dw = 0.7\ll 2\)</span> indicates positive autocorrelation.<br />
Negative autocorrelation is rare because the alternating pattern is unusual in economic data.</p>
</div>
<div id="c-6" class="section level3">
<h3>c</h3>
<blockquote>
<p>What are the effects of autocorrelation on the properties of the OLS estimator?<br />
Think about unbiasedness, consistency and the BLUE property.</p>
</blockquote>
<ol style="list-style-type: decimal">
<li>Unbiasedness is unaffected</li>
<li>Consistency is unaffected (?)</li>
<li>The OLS estimator is no longer BLUE because no autocorrelation among error terms (A4) is violated</li>
</ol>
</div>
<div id="d-6" class="section level3">
<h3>d</h3>
<blockquote>
<p>Describe two different approaches to handle the autocorrelation problem in the above case.<br />
Which one would you prefer?</p>
</blockquote>
<p>slide 7 P12</p>
<ol style="list-style-type: decimal">
<li>Reconsider the model: functional form or specification (preferred)</li>
<li>Use HAC standard error</li>
</ol>
<blockquote>
<p>From now on, assume that <span class="math inline">\(S_t\)</span> and <span class="math inline">\(Y_t\)</span> are nonstationary I(1) series.</p>
</blockquote>
</div>
<div id="e-6" class="section level3">
<h3>e</h3>
<blockquote>
<p>Are there indications that the relationship between the two variables is ‘spurious’?</p>
</blockquote>
<p>textbook P352, slide 12 P30</p>
<p>Yes because <span class="math inline">\(R^2\)</span> is high, <span class="math inline">\(β\)</span> is significant and dw is low.</p>
</div>
<div id="f-6" class="section level3">
<h3>f</h3>
<blockquote>
<p>Explain what we mean by ‘spurious regressions’.</p>
</blockquote>
<p>Two non-stationary process appear to be correlated because they are both trended, but without sensible causality.</p>
</div>
<div id="g-6" class="section level3">
<h3>g</h3>
<blockquote>
<p>Are there indications that there is a cointegrating relationship between <span class="math inline">\(S_t\)</span> and <span class="math inline">\(Y_t\)</span>?</p>
</blockquote>
<p>textbook P353, slide 12 P31</p>
<p><span class="math display">\[\begin{aligned}S_t &amp;= α + βY_t + ε_t \\
ε_t &amp;= S_t - α - βY_t\end{aligned}\]</span>
Since <span class="math inline">\(s = 22.57\)</span>, the sample variance of the residuals is relatively large,<br />
indicates no cointegrating relationship.</p>
</div>
<div id="h-5" class="section level3">
<h3>h</h3>
<blockquote>
<p>Explain what we mean by a ‘cointegrating relationship’.</p>
</blockquote>
<p><a href="https://en.wikipedia.org/wiki/Cointegration?oldformat=true">Cointegration - Wikipedia</a></p>
<p>Two non-stationary process are correlated, and their linear combination for some <span class="math inline">\(β\)</span> is stationary.</p>
</div>
<div id="i-5" class="section level3">
<h3>i</h3>
<blockquote>
<p>Describe two different tests that can be used to test the null hypothesis that <span class="math inline">\(S_t\)</span> and <span class="math inline">\(Y_t\)</span> are not cointegrated.</p>
</blockquote>
<p>textbook P354</p>
<ol style="list-style-type: decimal">
<li>ADF test</li>
<li>Cointegrating regression Durbin–Watson test</li>
</ol>
</div>
<div id="j-4" class="section level3">
<h3>j</h3>
<blockquote>
<p>How do you interpret the coefficient estimate of 0.098 under the hypothesis that <span class="math inline">\(S_t\)</span> and <span class="math inline">\(Y_t\)</span> are cointegrated?</p>
</blockquote>
<p>textbook P355</p>
<p>Cannot reject H0: <span class="math inline">\(S_t\)</span> and <span class="math inline">\(Y_t\)</span> are not cointegrated</p>
</div>
<div id="k-2" class="section level3">
<h3>k (*)</h3>
<blockquote>
<p>Are there reasons to correct for autocorrelation in the error term when we estimate a cointegrating regression?</p>
</blockquote>
</div>
<div id="l-2" class="section level3">
<h3>l (*)</h3>
<blockquote>
<p>Explain intuitively why the estimator for a cointegrating parameter is super-consistent.</p>
</blockquote>
</div>
<div id="m-2" class="section level3">
<h3>m (*)</h3>
<blockquote>
<p>Assuming that <span class="math inline">\(S_t\)</span> and <span class="math inline">\(Y_t\)</span> are cointegrated, describe what we mean by an error-correction mechanism.<br />
Give an example. What do we learn from it?</p>
</blockquote>
</div>
<div id="n-1" class="section level3">
<h3>n (*)</h3>
<blockquote>
<p>How can we consistently estimate an error-correction model?</p>
</blockquote>
</div>
</div>
<div id="exercise-9.3-cointegration---empirical" class="section level2">
<h2>Exercise 9.3 (Cointegration - Empirical)</h2>
<blockquote>
<p>In this exercise we employ quarterly data on UK nominal consumption and income, for 1971:I to 1985:II (T = 58).<br />
Part of these data was used in Exercise 8.3.</p>
</blockquote>
<div id="a-7" class="section level3">
<h3>a</h3>
<blockquote>
<p>Test for a unit root in the consumption series using several augmented Dickey–Fuller tests.</p>
</blockquote>
</div>
<div id="b-7" class="section level3">
<h3>b</h3>
<blockquote>
<p>Perform a regression by OLS explaining consumption from income.<br />
Test for cointegration using two different tests.</p>
</blockquote>
</div>
<div id="c-7" class="section level3">
<h3>c</h3>
<blockquote>
<p>Perform a regression by OLS explaining income from consumption.<br />
Test for cointegration.</p>
</blockquote>
</div>
<div id="d-7" class="section level3">
<h3>d</h3>
<blockquote>
<p>Compare the estimation results and <span class="math inline">\(R_2\)</span>’s from the last two regressions.</p>
</blockquote>
</div>
<div id="e-7" class="section level3">
<h3>e</h3>
<blockquote>
<p>Determine the error-correction term from one of the two regressions and estimate an error-correction model for the change in consumption.<br />
Test whether the adjustment coefficient is zero.</p>
</blockquote>
</div>
<div id="f-7" class="section level3">
<h3>f</h3>
<blockquote>
<p>Repeat the last question for the change in income.<br />
What do you conclude?</p>
</blockquote>
</div>
</div>

    </div>
  </article>
  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  (function() { 
  var d = document, s = d.createElement('script');
  s.src = 'https://loikein-github.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>

</main>
      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>

          <li>Theme by loikein with love</li>
        </ul>
      </footer>
    </div>
    
    <script src="https://hypothes.is/embed.js" async></script>
    
    
<script src="/js/math-code.js"></script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-143089736-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>
