<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.55.4" />

<title>Notes on Time Series - loikein</title>
<meta property="og:title" content="Notes on Time Series - loikein">


  


<link rel="icon" type="image/x-icon" href="/favicon.ico" />


<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">
<link rel="stylesheet" href="/css/clumsy-toc.css" media="all">




  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/loikein-logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>
  <ul class="nav-links">
    
    <li><a href="/">Posts</a></li>
    
    <li><a href="/tags/">Tags</a></li>
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/loikein/loikein.github.io">GitHub</a></li>
    
  </ul>
</nav>
      </header>
<main class="content" role="main">
  <article class="article">
    
    <span class="article-duration">7 min read</span>
    
    <h1 class="article-title">Notes on Time Series</h1>
    
    <span class="article-date">2019/04/15</span>
    
    
    
    <span class="tags">
    
    
    Tags:
    
    <a href='/tags/notes'>notes</a>
    
    <a href='/tags/r'>R</a>
    
    <a href='/tags/stat'>stat</a>
    
    
    
    </span>
    
    <div class="article-content">
      

<div id="TOC">
<ul>
<li><a href="#definition">Definition</a><ul>
<li><a href="#property">Property</a></li>
</ul></li>
<li><a href="#analysis">Analysis</a><ul>
<li><a href="#procedure">Procedure</a></li>
<li><a href="#trend">Trend</a></li>
<li><a href="#trend-seasonality">Trend &amp; Seasonality</a></li>
<li><a href="#lag-difference-operator">Lag &amp; Difference Operator</a></li>
</ul></li>
<li><a href="#arma">ARMA</a><ul>
<li><a href="#white-noise">White Noise</a></li>
<li><a href="#ma">MA</a></li>
<li><a href="#stationarity">Stationarity</a></li>
<li><a href="#ar">AR</a></li>
</ul></li>
<li><a href="#old-stuff">Old Stuff</a><ul>
<li><a href="#integration">Integration</a></li>
<li><a href="#ols-estimation">OLS Estimation</a></li>
<li><a href="#ml-estimation">ML Estimation</a></li>
<li><a href="#model-selection">Model Selection</a></li>
<li><a href="#spurious-regression">Spurious Regression</a></li>
<li><a href="#cointegration">Cointegration</a></li>
</ul></li>
</ul>
</div>

<div id="definition" class="section level2">
<h2>Definition</h2>
<ul>
<li>Time series: collection of observations indexed by date
<span class="math display">\[\begin{aligned}\{y_t\}_{t=-\infty}^{\infty} &amp;= \{y_t\}_{t\in\mathbb{Z}} \\
&amp;= \{ \dots, y_{-1}, y_0, y_1, y_2,\dots, y_{T-1}, y_{T}, y_{T+1},\dots\} \end{aligned}\]</span>
<ul>
<li>Observed sample: <span class="math inline">\(\{ y_1, y_2,\dots, y_{T-1}, y_{T}\}\)</span></li>
<li>Underlying random variables: <span class="math inline">\(\{ Y_1, Y_2,\dots, Y_{T-1}, Y_{T}\}\)</span></li>
</ul></li>
<li>Stochastic process: ordered sequence of random variables
<span class="math display">\[\{Y_t\}_{t=0,\pm 1,\pm 2,\dots} =\{Y_t\}_{t\in\mathbb{Z}}\]</span>
<ul>
<li>Probability space: <span class="math inline">\((Ω,\mathcal{A},P)\)</span></li>
<li>Mapping: <span class="math inline">\(\{Y_t(\cdot)\}: Ω\mapsto \mathbb{R}^{\mathbb{Z}}\)</span> s.t. <span class="math inline">\(\{Y_t(ω) \}_{t\in\mathbb{Z}} = \{Y_t(ω) : t\in\mathbb{Z} \}\)</span></li>
<li>Fix <span class="math inline">\(t\)</span>, vary <span class="math inline">\(ω\implies\)</span> scalar random variable <span class="math inline">\(Y_t(ω)\)</span></li>
<li>Fix <span class="math inline">\(ω\)</span>, vary <span class="math inline">\(t\implies\)</span><br />
Trajectory (realization): <span class="math inline">\(\{ y_1, y_2,\dots, y_{T-1}, y_{T}\}\)</span></li>
</ul></li>
</ul>
<div id="property" class="section level3">
<h3>Property</h3>
<ul>
<li>First moment: <span class="math inline">\(μ_t = E[Y_t]\)</span></li>
<li>Second moments
<ul>
<li>Variance: <span class="math inline">\(γ_{0t} = E\big[(Y_t - μ_t)^2\big]\)</span></li>
<li>Covariance: <span class="math inline">\(γ_{jt} = E\big[(Y_t - μ_t)(Y_{t-j} - μ_{t-j})\big]\)</span></li>
<li><span class="math inline">\(E[Y_t^2]&lt;\infty\implies γ_{jt}&lt;\infty\)</span></li>
</ul></li>
<li>Weakly (Covariance) Stationary
<span class="math display">\[\begin{cases} E[Y_t] = μ &lt; \infty &amp; \text{for all }t \\
Var(Y_t) = γ_0 &lt; \infty &amp; \text{for all }t\\
Cov(Y_t, Y_{t-j}) = γ_j &amp; \text{for all }t,j\end{cases}\]</span>
<ul>
<li><span class="math inline">\(γ_{j,t} = γ_{j,t+s}\)</span> for all <span class="math inline">\(t,s\)</span></li>
</ul></li>
<li>AutoCorrelation Function (ACF)
<span class="math display">\[ρ_j = \frac{Cov(Y_t,Y_{t-j})}{Var(Y_t)} = \frac{γ_j}{γ_0}\]</span>
<ul>
<li>Sample ACF: <span class="math display">\[\hat{ρ}_j = \frac{\frac{1}{T-j}\sum^T_{t=j+1}(Y_t-\bar{Y})(Y_{t=j}-\bar{Y})}{\frac{1}{T}\sum^T_{t=1}(Y_t-\bar{Y})^2}\]</span></li>
<li><span class="math inline">\(\sqrt{T}(\hat{ρ}_j-ρ_j)\to\mathcal{N}(0,\exists v_k)\)</span></li>
</ul></li>
<li>Ergodicity for the mean<br />
For stationary process <span class="math inline">\(Y_t\)</span>,
<span class="math display">\[\begin{aligned}\bar{Y}_T &amp;= \frac{1}{T}\sum_T y_t \\
&amp;\overset{p}{\to}μ &amp;&amp; T\to\infty\end{aligned}\]</span>
<ul>
<li>Let <span class="math inline">\(Y_t\)</span> be s.t. <span class="math inline">\(\sum_{\infty} |γ_j|&lt;\infty\)</span>, then <span class="math inline">\(Y_t\)</span> is ergodic</li>
</ul></li>
</ul>
</div>
</div>
<div id="analysis" class="section level2">
<h2>Analysis</h2>
<div id="procedure" class="section level3">
<h3>Procedure</h3>
<ol style="list-style-type: decimal">
<li>Plot and check for
<ul>
<li>Trend</li>
<li>Seasonality</li>
<li>Abrupt changes</li>
<li>Outliers</li>
</ul></li>
<li>Remove the trend and seasonality to obtain stationary residuals</li>
<li>Choose a model to fit the residuals (ARMA, GARCH)</li>
<li>Forecast the residuals</li>
<li>Invert transformations to forecast the original series</li>
</ol>
</div>
<div id="trend" class="section level3">
<h3>Trend</h3>
<ul>
<li>Model with trend
<span class="math display">\[\begin{aligned}Y_t &amp;= \underbrace{m_t}_{\text{Trend component}} + \underbrace{X_t}_{\text{Random noise component}} \\
E[X_t] &amp;= 0\end{aligned}\]</span></li>
<li>Moving average filter<br />
For <span class="math inline">\(t = q+1, q+2,\dots, T-q\)</span>,
<span class="math display">\[\begin{aligned}\hat{m}_t &amp;= \frac{1}{2q+1}\sum_{j=-q}^q Y_{t-j} \\
&amp;= \frac{1}{2q+1}\sum_{j=-q}^q m_{t-j} + \frac{1}{2q+1}\sum_{j=-q}^q X_{t-j} \\
&amp;\approx m_t \\
Y_t - \hat{m}_t &amp;\approx X_t \end{aligned}\]</span></li>
<li>Exponential smoothing (better for forecasting)
<span class="math display">\[\begin{aligned}\hat{m}_1 &amp;= Y_1 \\
\hat{m}_t &amp;= αY_t  + (1-α)\hat{m}_{t-1} \\
&amp;= \sum_{j=0}^{t-2}α(1-α)^jY_{t-j}  + (1-α)^{t-1}Y_1\end{aligned}\]</span></li>
<li>Polynomial fitting<br />
Let <span class="math display">\[m_t = a_0 + a_1t+ a_2t^2 + \dots\]</span>
Choose <span class="math inline">\(a\)</span>’s as
<span class="math display">\[\begin{aligned}(\hat{a}_0, \hat{a}_1, \hat{a}_2,\dots) &amp;= \text{argmin} \ \sum^T_{t=1}(Y_t - m_t)^2 \\
\hat{m}_t &amp;= \hat{a}_0 + \hat{a}_1t + \hat{a}_2t^2 + \dots\end{aligned}\]</span></li>
<li>Elimination<br />
For polynomial trend, choose <span class="math inline">\(k\)</span> s.t.
<span class="math display">\[\begin{aligned}m_t &amp;= a_0 + a_1t + \dots + a_kt^k \\
Δ^km_t &amp;= k!a_k \\
Δ^k Y_t &amp;= Δ^km_t + Δ^X_t \\
&amp;= k!a_k + Δ^X_t \\
E[Δ^k Y_t] &amp;= k!a_k\end{aligned}\]</span></li>
</ul>
</div>
<div id="trend-seasonality" class="section level3">
<h3>Trend &amp; Seasonality</h3>
<ul>
<li>Model with trend &amp; seasonality (period <span class="math inline">\(d\)</span>)
<span class="math display">\[\begin{aligned}Y_t &amp;= m_t + \underbrace{s_t}_{\text{Seasonal component}} + X_t \\
E[X_t] &amp;= 0 \\
s_{t+d} &amp;= s_t \\
\sum_{j=1}^d s_j &amp;= 0 \end{aligned}\]</span></li>
<li>Estimation
<ol style="list-style-type: decimal">
<li>Estimate trend (moving average)<br />
For <span class="math inline">\(t = q+1, q+2,\dots, T-q\)</span>, when <span class="math inline">\(d = 2q\)</span><br />
<span class="math display">\[\begin{aligned}\hat{m} &amp;= \frac{1}{d}\Big(\frac{1}{2}Y_{t-q} + Y_{t-(q-1)} + \dots + Y_{t+(q-1)} + \frac{1}{2}Y_{t+q} \Big) \\ \end{aligned}\]</span>
When <span class="math inline">\(d = 2q+1\)</span><br />
<span class="math display">\[\begin{aligned}\hat{m}_t &amp;= \frac{1}{d}\sum_{j=-q}^q Y_{t-j}\end{aligned}\]</span></li>
<li>Estimate seasonal component<br />
For <span class="math inline">\(t = 1, 2,\dots, d\)</span><br />
<span class="math display">\[\begin{aligned}w_t &amp;= \frac{1}{\#\{j: q&lt;t+jd \leq T-q\}}\sum_{j: q&lt;t+jd \leq T-q} (Y_{t+jd} - \hat{m}_{t+jd}) \\
  \hat{s}_t &amp;= w_t - \frac{1}{d}\sum_{i=1}^d w_i\end{aligned}\]</span></li>
<li>Re-estimate trend<br />
De-seasonalized data:
<span class="math display">\[\begin{aligned}d_t &amp;= Y_t - \hat{s}_t \\
  \hat{X}_t &amp;= Y_t - \hat{m}_t - \hat{s}_t \end{aligned}\]</span></li>
</ol></li>
<li>Elimination<br />
First liminate seasonality:
<span class="math display">\[\begin{aligned}Δ_d Y_t &amp;= Y_t - Y_{t-d} \\
&amp;= m_t - m_{t-d} + X_t - X_{t-d} \end{aligned}\]</span>
Then <a href="#trend">#eliminate trend</a></li>
</ul>
</div>
<div id="lag-difference-operator" class="section level3">
<h3>Lag &amp; Difference Operator</h3>
<ul>
<li>Lag operator: <span class="math inline">\(L^0=1\)</span>, <span class="math inline">\(Ly_t = y_{t-1}\)</span>, <span class="math inline">\(L^2 y_t = y_{t-2}\)</span>, …
<ul>
<li>Lag polynomial
<span class="math display">\[\begin{aligned} θ(L) &amp;= 1 - θ_1L - θ_2L^2 -\cdots - θ_pL^p \\
  y_t &amp;= θ_1Ly_t -\cdots - θ_p L^p y_t + ε_t \\
  θ(L) y_t &amp;= ε_t\end{aligned}\]</span></li>
</ul></li>
<li>Difference operator: <span class="math inline">\(Δ=1-L\)</span>, <span class="math inline">\(Δ^k = (1-L)^k\)</span>
<ul>
<li>Difference polynomial
<span class="math display">\[\begin{aligned}Δ^2 y_t &amp;= Δ(Δ y_t) \\
  &amp;= (1-L)(1-L)y_t \\
  &amp;= (1-2L +L^2)y_t \\
  &amp;= y_t - 2y_{t-1} + y_{t-2}\end{aligned}\]</span></li>
</ul></li>
<li>Lag-<span class="math inline">\(d\)</span> differencing operator: <span class="math inline">\(Δ_d = (1 - L^d)\)</span></li>
</ul>
</div>
</div>
<div id="arma" class="section level2">
<h2>ARMA</h2>
<div id="white-noise" class="section level3">
<h3>White Noise</h3>
<ul>
<li>Gaussian White Noise: <span class="math inline">\(ε_t\overset{iid.rvs}{\sim}\mathcal{N}(0,σ^2)\)</span>
<ul>
<li>White Noise: <span class="math inline">\(ε_t\overset{iid.rvs}{\sim}(0,σ^2)\)</span></li>
<li>Stationary</li>
</ul></li>
<li>Random walk <span class="math display">\[Y_t = \sum_{s=1}^t ε_s\]</span>
<ul>
<li>Not stationary
<span class="math display">\[\begin{aligned}\text{Mean:} &amp;&amp; E[Y_t] &amp;= 0 \\
\text{Variance:} &amp;&amp; Var(Y_t) &amp;= tσ^2 \\
\text{Covariance:} &amp;&amp; Cov(Y_t,Y_{t-j}) &amp;= 0 \\
\text{ACF:} &amp;&amp; Corr(Y_t,Y_{t-j}) &amp;= \frac{Cov(Y_t,Y_{t-j})}{Var(Y_t)}= 0\end{aligned}\]</span></li>
</ul></li>
</ul>
</div>
<div id="ma" class="section level3">
<h3>MA</h3>
<ul>
<li>MA (1) <span class="math display">\[Y_t = μ + ε_t + θε_{t-1}\]</span>
<span class="math display">\[\begin{aligned}\text{Mean:} &amp;&amp; E[Y_t] &amp;= μ \\
\text{Variance:} &amp;&amp; Var(Y_t) &amp;= σ^2\cdot (1 + θ^2) \\
\text{Covariance:} &amp;&amp; Cov(Y_t,Y_{t-j}) &amp;= \begin{cases} θσ^2 &amp; j=1\\ 0 &amp; j\geq 2\end{cases} \\
\text{ACF:} &amp;&amp; Corr(Y_t,Y_{t-j}) &amp;= \begin{cases} \frac{θ}{1 + θ^2} \leq \frac{1}{2} &amp; j=1\\ 0 &amp; j\geq 2\end{cases}\end{aligned}\]</span></li>
<li>MA (q)
<span class="math display">\[\begin{aligned}Y_t &amp;= μ + ε_t + θ_1 ε_{t-1} +\cdots + θ_q ε_{t-q} \\
&amp;= μ + \sum_{j=0}^q θ_j ε_{t-j}\end{aligned}\]</span>
<span class="math display">\[\begin{aligned}\text{Mean:} &amp;&amp; E[Y_t] &amp;= μ \\
\text{Variance:} &amp;&amp; Var(Y_t) &amp;= σ^2\cdot (1 + θ_1^2 + θ_2^2 + \dots + θ_q^2) \\
\text{Covariance:} &amp;&amp; Cov(Y_t,Y_{t-j}) &amp;= \begin{cases} σ^2\cdot\sum_{i=0}^{q-j} θ_iθ_{i+j} &amp; 0\leq j\leq q\\ 0 &amp; j &gt; q\end{cases} \\
\text{ACF:} &amp;&amp; Corr(Y_t,Y_{t-j}) &amp;= \begin{cases} ? &amp; 0\leq j\leq q\\ 0 &amp; j &gt; q\end{cases}\end{aligned}\]</span></li>
<li>MA (<span class="math inline">\(\infty\)</span>)
<span class="math display">\[Y_t = μ + \sum_{j=0}^{\infty} ψ_j ε_{t-j}\]</span>
<span class="math display">\[\begin{aligned}\text{Mean:} &amp;&amp; E[Y_t] &amp;= μ \\
\text{Variance:} &amp;&amp; Var(Y_t) &amp;= σ^2\cdot \sum_{i=0}^{\infty} ψ_i^2 = γ_0 \\
\text{Covariance:} &amp;&amp; Cov(Y_t,Y_{t-j}) &amp;= σ^2\cdot\sum_{i=0}^{\infty} ψ_iψ_{i+j} = γ_j \\
\text{ACF:} &amp;&amp; Corr(Y_t,Y_{t-j}) &amp;= ?\end{aligned}\]</span></li>
</ul>
</div>
<div id="stationarity" class="section level3">
<h3>Stationarity</h3>
<p>Reference:<br />
<a href="http://www.real-statistics.com/time-series-analysis/autoregressive-processes/characteristic-equation-autoregressive-processes/">Characteristic Equation AR (p) | Real Statistics Using Excel</a><br />
<a href="https://stats.stackexchange.com/questions/208656/intuition-behind-the-characteristic-equation-of-an-ar-or-ma-process">Intuition behind the characteristic equation of an AR or MA process</a></p>
<ul>
<li>Absolute summability
<span class="math display">\[\begin{aligned}\sum_{j=0}^{\infty} |ψ_j| &amp;&lt; \infty \\
\implies\sum_{j=0}^{\infty} |γ_j| &amp;&lt; \infty \end{aligned}\]</span></li>
<li>Square summability <span class="math display">\[\sum_{j=0}^{\infty} ψ_j^2 &lt; \infty\]</span></li>
<li>Causal form <span class="math inline">\(ε_t\)</span><br />
<span class="math inline">\(\iff \{Y_t\}\)</span> has a covariance-stationary representation
<span class="math display">\[\begin{aligned}&amp;Y_t = μ + \sum_{j=0}^{\infty} ψ_j ε_{t-j} \\
&amp;\sum_{j=0}^{\infty} |ψ_j| &lt; \infty\end{aligned}\]</span></li>
<li>Linear process<br />
<span class="math inline">\(\{ε_t\}\)</span> is stationary <span class="math inline">\(\implies\{Y_t\}\)</span> is stationary
<span class="math display">\[\begin{aligned}Y_t = μ + \sum_{j=-\infty}^{\infty} ψ_j ε_{t-j} \\
&amp;ψ = 1 \\
&amp;\sum_{j=-\infty}^{\infty} |ψ_j| &lt; \infty\end{aligned}\]</span></li>
<li>Characteristic root
<span class="math display">\[|z|\begin{cases}&lt;1 &amp; \text{explosive} \\ =1 &amp; \text{unit root (explosive)} \\ &gt;1 &amp; \text{stationary}\end{cases}\]</span></li>
<li>AR (1) is stationary <span class="math inline">\(\iff 1-φL\)</span> is invertible <span class="math inline">\(\iff |z| &gt; 1\)</span><br />
<span class="math inline">\(\Longleftarrow \ |φ|&lt;1\)</span>
<span class="math display">\[\begin{aligned} y_t &amp;= φLy_t + ε_t \\
(1-φL) y_t &amp;= ε_t \\
1 - φ\cdot z &amp;= 0 \\
|z| &amp;= \Bigg| \frac{1}{φ}\Bigg|&gt; 1 \\
|φ| &amp;&lt; 1\end{aligned}\]</span></li>
<li>AR (p) has a covariance-stationary representation<br />
<span class="math inline">\(\iff |z|&gt;1\)</span> for all characteristic roots <span class="math inline">\(z\)</span> in <strong>characteristic equation</strong><br />
<span class="math inline">\(\Longleftarrow \ \sum_{j=1}^p φ_j &lt;1\)</span><br />
<span class="math display">\[\begin{aligned}y_t &amp;= φ_1Ly_t -\cdots - φ_p L^p y_t + ε_t \\
φ(L) &amp;= 1 - φ_1L - φ_2L^2 -\cdots - φ_pL^p \\
φ(L) y_t &amp;= ε_t \\
1 - φ_1z - φ_2z^2 - \dots - φ_pz^p &amp;= 0 \\
|z| &amp;= \Big|\frac{1}{φ_1L + φ_2L^2 + \cdots + φ_pL^p}\Big| \\
&amp;= \Bigg|\frac{1}{\sum_{j=1}^p φ_jL^j}\Bigg| \\
&amp;= \Bigg|\frac{1}{\sum_{j=1}^p φ_j}\Bigg| &gt; 1 \\
\Big|\sum_{j=1}^p φ_j\Big| &amp;&lt; 1\end{aligned}\]</span></li>
</ul>
</div>
<div id="ar" class="section level3">
<h3>AR</h3>
<ul>
<li>AR (1)
<span class="math display">\[\begin{aligned}Y_t &amp;= c + φ Y_{t-1} + ε_t \\
&amp;= c  + ε_t + φ\cdot(c + φY_{t-2} + ε_{t-1}) \\
&amp;= c + φc + ε_t + φ ε_{t-1} + φ^2Y_{t-2} \\
&amp;= c + φc + \dots + φ^j c \\
&amp;\phantom{\ggg} + ε_t + φε_{t-1} +\dots + φ^jε_{t-j} + φ^{j+1}Y_{t-(j+1)} \\
&amp;= c\cdot\sum_{j=0}^{\infty} φ^j + \sum_{j=0}^{\infty} φ^j\cdot ε_{t-j}\end{aligned}\]</span>
When <span class="math inline">\(|φ|&lt;1\)</span>, <span class="math inline">\(φ^{j+1}Y_{t-(j+1)}\to 0\)</span> as <span class="math inline">\(j\to\infty\)</span>, AR (1) becomes MA (<span class="math inline">\(\infty\)</span>)
<ul>
<li>Absolute summability</li>
<li>Stationary
<span class="math display">\[\begin{aligned}MA(\infty) &amp;&amp; Y_t &amp;= μ + \sum_{j=0}^{\infty} ψ_j\cdot ε_{t-j} \\
  AR(1) &amp;&amp; Y_t &amp;= \frac{c}{1-φ} + \sum_{j=0}^{\infty} φ^j\cdot ε_{t-j} \\
  \text{Mean:} &amp;&amp; E[Y_t] &amp;= \frac{c}{1-φ} = μ \\
  \text{Variance:} &amp;&amp; Var(Y_t) &amp;= \frac{σ^2}{1-φ^2} = γ_0 \\
  \text{Covariance:} &amp;&amp; Cov(Y_t,Y_{t-j}) &amp;= \frac{σ^2φ^j}{1-φ^2}  = γ_j \\
  \text{ACF:} &amp;&amp; Corr(Y_t,Y_{t-j}) &amp;= φ^j\end{aligned}\]</span></li>
</ul></li>
<li>AR (p)
<span class="math display">\[Y_t = c + φ_1 Y_{t-1} +\cdots + φ_p Y_{t-p} + ε_t\]</span></li>
<li>ARMA (p,q)
<span class="math display">\[Y_t = θ_1Y_{t-1} +\cdots + θ_pY_{t-p} + ε_t + α_1 ε_{t-1} +\cdots + α_q ε_{t-q}\]</span></li>
</ul>
<!-- 
$$\begin{aligned}\text{Mean:} && E[Y_t] &= δ + θ E[Y_{t-1}] \\
&& &= \frac{δ}{1-θ} \\ 
&& &= μ \\
\text{Variance:} && Var(Y_t) &= θ^2Var(Y_{t-1}) + Var(ε_t) \\
&& &= \frac{σ^2}{1-θ^2} \\
\text{Covariance:} && Cov(Y_t,Y_{t-j}) &= θ^k\frac{σ^2}{1-θ^2} \\
\text{ACF:} && Corr(Y_t,Y_{t-j}) &= \frac{Cov(Y_t,Y_{t-j})}{Var(Y_t)} \\
&& &= θ^k \end{aligned}$$
 -->
</div>
</div>
<div id="old-stuff" class="section level2">
<h2>Old Stuff</h2>
<div id="integration" class="section level3">
<h3>Integration</h3>
<ul>
<li><span class="math inline">\(I(0)\)</span> denotes stationary series
<ul>
<li>Mean reverting</li>
<li>Finite variance</li>
<li>Limited memory of past behaviour</li>
</ul></li>
<li><span class="math inline">\(I(1)\)</span> denotes series that become stationary after first-differencing
<ul>
<li>Infinitely long memory</li>
</ul></li>
</ul>
<!--
### Deterministic (Linear) Trend

- Another possible cause of nonstationarity: $γ\neq 0$ (even when $|θ|<1$) 
$$Y_t = δ + θY_{t-1}+γ\cdot t + ε_t$$ 
- Trend stationary
- Solution: 
    - Regress $Y_t$ on constant and trend and then use residuals  
    - include $t$ as additional variable in regression
-->
</div>
<div id="ols-estimation" class="section level3">
<h3>OLS Estimation</h3>
<ul>
<li>For AR (p)
<ul>
<li>Consistency: <span class="math inline">\(E[Y_{t-j}ε_t] = 0\)</span> for all <span class="math inline">\(j = 1,2,3,\dots,p\)</span><br />
</li>
<li>Small sample bias caused ((A2) violated)</li>
</ul></li>
<li>For MA (1) with invertible lag polynomial
<ul>
<li>tbe</li>
</ul></li>
</ul>
</div>
<div id="ml-estimation" class="section level3">
<h3>ML Estimation</h3>
<p>tbe</p>
</div>
<div id="model-selection" class="section level3">
<h3>Model Selection</h3>
<ul>
<li>Residual analysis (Ljung–Box test)</li>
<li>AIC &amp; BIC</li>
<li>Overfitting: to test ARMA (p,q), estimate ARMA (p+1,q) and ARMA (p,q+1)</li>
</ul>
</div>
<div id="spurious-regression" class="section level3">
<h3>Spurious Regression</h3>
<p>textbook P352, slide 12 P28</p>
</div>
<div id="cointegration" class="section level3">
<h3>Cointegration</h3>
<p>textbook P353, slide 12 P31<br />
<a href="http://staff.utia.cas.cz/barunik/files/appliedecono/Lecture7.pdf">Lecture: Introduction to Cointegration - Applied Econometrics</a></p>
<ul>
<li>Cointegration <span class="math inline">\(\implies\)</span> not spurious</li>
</ul>
</div>
</div>

    </div>
  </article>
  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  (function() { 
  var d = document, s = d.createElement('script');
  s.src = 'https://loikein-github.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>

</main>
      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>

          <li>By loikein with love</li>
        </ul>
      </footer>
    </div>
    
    
    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>

    
  </body>
</html>